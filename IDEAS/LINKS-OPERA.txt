http://www.forth.org/Stundurd.txt


title:      the Stundurd micro-processor

author:     Hugh Aguilar

date:       October 20, 2015


about the author:
            Hugh Aguilar wrote the MFX assembler, simulator and cross-compiler for the MiniForth (now called RACE) processor at Testra.
            The MiniForth/RACE is described here: http://www.testra.com/Forth/RACE.htm
            Hugh Aguilar is also the author of the ANS-Forth novice package: http://www.forth.org/novice.html
            He may be contacted at: hughaguilar96@yahoo.com


abstract:

The Stundurd is a design for a byte-code Forth micro-processor with a 16-bit wide parameter-stack to be implemented in an FPGA (this is an upgrade on the previous FMITE design). Its primary virtue is compact machine-code. The maximum memory is 32KB non-volatile and 32KB RAM. A primitive call is an 8-bit instruction (there are 64 primitives). A short literal is an 8-bit instruction (the short literal is in the [0,31] range). A long literal is a 16-bit instruction (the long literal is in the [0,4095] range). The CALL is in the [16384,32767] range. It is possible to fetch out of constant-memory (but not store) and store into program-memory (but not fetch). The Stundurd is intended to have a small physical size, low power consumption and low price. It should be reasonably fast. In a big FPGA, rather than have a big 32-bit processor, it would be better to have two or more 16-bit Stundurd processor cores with some common memory; the WEXCH-GP instruction can be used for reading and writing a semaphore, as it is guaranteed to lock-out the common-memory during its execution. The Stundurd has local variables that work with either single-cell or double-cell values. It has quotations (a kind of lambda function) that have access to the parent function's local variables. Quotations allow for general-purpose data-structures, which are necessary for reusable code libraries. The hope with the Stundurd is that Forthers can finally get away from writing every program entirely from scratch (or, worse, cut-and-paste from previous programs) --- by allowing programs to be written using code libraries, Forth can become a professional-grade language more practical than C or ANS-Forth. In order to dodge the disrepute of Standard Forth (ANS-Forth and now Forth-200x), the name of the language will Stundurd Forth --- it is idiomatic in Stundurd Forth to use higher-order functions for iteration (Stundurd Forth doesn't have DO loops) --- Stundurd Forth differs from Standard Forth in fundamental ways, so it needs a distinctive name.


section 1.) the registers

GPL     16-bit  general-purpose
GPH     16-bit  general-purpose
SOS     16-bit  second value of PS parameter-stack
TOS     16-bit  top value of PS parameter-stack
PS       7-bit  parameter-stack pointer                 in the format: 10000000xxxxxxx0     128 cells in the range [$8000,$80FE] cell-aligned
RS       7-bit  return-stack pointer                    in the format: 10000001xxxxxxx0     128 cells in the range [$8100,$81FE] cell-aligned
FP       7-bit  frame pointer                           in the format: 10000001xxxxxxx0     same range as RS (because local frames are in the return stack)
IP      15-bit  instruction pointer                     in the format: 0xxxxxxxxxxxxxxx     covers the 32KB non-volatile memory (lower 32KB)

In some versions of the Stundurd, there is another 16-bit register called RTOS that holds the top value of the return-stack. If the RTOS register is provided, the implementation of all the primitives that access the return-stack will need to be changed from what is described in this document. The behavior of these primitives will be the same however, so all Stundurd code will run unchanged whether the Stundurd processor has the RTOS register or not. Given the RTOS register, the RFETCH12 primitive will be significantly faster. It is idiomatic to hold a struct pointer on the return-stack and use R@ to get its address when needed.

When an interrupt occurs, GPL GPH SOS TOS and IP are all saved on the return-stack. The RETURN-ISR function restores these. Interrupts only occur between the execution of the instructions (primitives). We don't have any instructions for masking and unmasking interrupts, or going into sleep mode, or resetting a COP (computer-operating-properly) timer. It is possible that some of the I/O ports mapped to the lower 32 bytes of data-memory can, when written to, perform these functions. It also hasn't been figured out yet how many levels of interrupts there will be, or where their vectors will be (presumably at the top of constant-memory). All of this interrupt structure will depend upon what the HDL programmer can do with the FPGA --- there may also be different versions of the Stundurd for various FPGAs that have various capabilities.

In a big FPGA, we may have multi-core Stundurd processors running concurrently. They would have a segment of memory that is common to them all. The WEXCH-GP instruction can be used for reading and writing a semaphore, as it is guaranteed to lock-out the common-memory from the other processors when it is executing. If another core attempts to execute any instruction that involves reading or writing to common-memory while one core is executing WEXCH-GP, that instruction will hang until WEXCH-GP finishes and unlocks the memory, and then it will do its read or write and continue. The idea is that we have a semaphore that is set to TRUE if any core has possession of the common-memory or FALSE if no core has possession of the common-memory (TRUE means "held"). If a core needs to access the common-memory, it uses WEXCH-GP to set the semaphore to TRUE and read what was in the semaphore. If it reads that the semaphore was TRUE already, then it knows that another core has possession of the common-memory (setting the semaphore to TRUE when it already was TRUE is redundant), so it continues doing this with WEXCH-GP repeatedly until it reads a FALSE. At this time, the core has possession of the common-memory (it set the semaphore to TRUE to block any other cores), and it does whatever it needs to do with common-memory, and afterward it sets the semaphore to FALSE (using CSTORE or whatever) to release possession of common-memory. Each core would hold the common-memory for as short of a time as possible (it would typically do its I/O out of its own memory, and only hold the common-memory long enough to WMOVE a block of data to or from). It is not necessary to SLEEP while waiting for access to the common memory because it should only be a short time to wait. It is possible to have multiple semaphores each representing possession of a segment of common-memory, rather than a single semaphore representing possession of the entire common memory. A multi-core system is much more powerful than a single-core system that uses interrupts for I/O. In a multi-core system, interrupts are not needed at all. In such a system, there would be no RETURN-ISP instruction, but instead (using that same opcode) there would be a SLEEP instruction. In a dual-core system, one core would be the main program and the other core would be the I/O handler. The main-program would sleep if there is no data available for it to work with (nothing has been input), and it would wake up when its READY flag gets set by the other core. The I/O handler would be on a timer and it would periodically execute, at which time it would input or output any data that is ready to be input or output, and it might set the READY flag for the main-program if it has input some data that the main program needs to do something about. The I/O handler would effectively be a paced loop. A dual-core system such as this, using two small Stundurd processors, is actually much better than a single-core system using a more powerful processor --- there is less chance of timing conflicts (in a single-core system, bad luck might cause multiple interrupts to happen at the same time, and some of those interrupts get lost and/or the main program delays too long causing a noticable stutter). Also, with a dual-core system, there is no need to worry about losing interrupts during the execution of time-consuming primitives such as UMULT22 or UDIV21 --- because there are no interrupts!

Every colon word has two versions of itself:
1.) Start with TOS valid and the rest in memory, and finish with TOS valid and the rest in memory (this is the version in the xt that EXECUTE will execute).
2.) Start with SOS and TOS valid and the rest in memory, and finish with TOS valid and the rest in memory.

The xt of a colon word contains the cfa of the #1 version for the benefit of EXECUTE. The cross-compiler will compile a CALL to either the #1 or #2 version, depending upon whether the code prior to the CALL has only TOS valid or has SOS and TOS valid. In assembly-language, we have CALL and CALL21 instructions. These actually both compile into the same primitive CALL --- the difference is whether they call the #1 or #2 version of the function. All functions return with only TOS valid.

One of the much-touted features of modern C compilers is that they allow passing parameters into functions via registers. This is as compared to the C compilers of 20 years ago that required a local-frame to be built for every function call. Stundurd also allows passing parameters into functions via registers. We only have two registers, SOS and TOS, so the rest of the data-stack has to be in memory, but this is still better than typical Forth compilers that have only the top value of the data-stack in a register. For example, consider this function:

: nd+  \ a b -- a b a+b
    ddup + ;

Stundurd Forth doesn't use the round-bracket ( for comments (as done in ANS-Forth, and all other Forths) --- the \ is used for comments.

In Stundurd, this compiles as:
s" nd+" header          \ CALL calls this version of ND+ when the calling function only has TOS valid (also, this is the version that EXECUTE executes)
    HUFF12              \ this expects TOS to be valid, and leaves SOS and TOS valid
s" nd+" header21        \ CALL21 calls this version of ND+ when the calling function already has SOS and TOS valid
    DDUP22              \ this expands as: OVER22 OVER22
    PLUS21              \ this expects SOS and TOS to be valid, and leaves only TOS valid
    RETURN

If only TOS is valid, the the first version of ND+ should be called:
    ND+ CALL
If SOS and TOS are already valid, then the second version of ND+ should be called:
    ND+ CALL21

In this article, "push" means to push a register to the parameter-stack in memory: subtract 2 from PS, then move register to (PS)
And "pull" means to pull a register from the parameter-stack in memory: move (PS) to register, then add 2 to PS
It is also possible to push and pull data to the return-stack; we will explicitly say "push to the return-stack" or "pull from the return-stack" to avoid confusion with the terms "push" and "pull" that mean to and from the parameter-stack.

It is assumed that accessing registers is significantly faster than accessing memory. We have some primitives (called "huffers") that expect the stack to be in the normal state, but they leave SOS holding data. We also have some primitives (called "puffers") that expect SOS to hold data, but leave the stack in the normal state. By pairing huffers with puffers, the code is optimized because we avoid pushing a register in one instruction, only to pull that same data into that same register in the next instruction (note that "optimized" is the typical programming term for improving efficiency, although it doesn't mean that the code is  actually optimal).


section 2.) the instruction format

The instructions are either 8-bit or 16-bit:

00xxxxxx            primitive       implemented in hardware; there are 64 of these.
010vvvvv            SLIT12          move TOS to SOS,    then move a literal value to TOS                                        vvvvv is in the range: [0,31]
011vvvvv            SLIT            push TOS,           then move a literal value to TOS                                        vvvvv is in the range: [0,31]
1000vvvv            LSHR            logical shift TOS right by vvvv bits (fill upper bits with 0)                                vvvv is in the range: [0,15]
1001vvvv            LSHL            logical shift TOS left  by vvvv bits (fill lower bits with 0)                                vvvv is in the range: [0,15]
1010000rrrrrrrrr    BRANCH          add a signed literal to IP.                                                            rrrrrrrrrr is in the range: [-256,255]
1010001vvvvvvvvv    LIT-PLUS        add a signed literal to TOS.                                                            vvvvvvvvv is in the range: [-256,255]
10100100vvvvvvvv    LIT-AND         logical-and a literal to TOS.                                                            vvvvvvvv is in the range: [0,255]
10100101vvvvvvvv    LIT-IOR         logical-inclusive-or a literal to TOS.                                                   vvvvvvvv is in the range: [0,255]
10100110vvvvvvvv    LIT-EOR         logical-exclusive-or a literal to TOS.                                                   vvvvvvvv is in the range: [0,255]
10100111000rrrrr    GP>LOCAL        move literal to SOS, then shift SOS left by two bits, then negate SOS, then add FP to SOS,        uses SOS internally
                                    then move GPL to (SOS), , then add 2 to SOS, then move GPH to (SOS)                         rrrrr is in the range: [0,31]
10100111001rrrrr    LOCAL>GP        move literal to SOS, then shift SOS left by two bits, then negate SOS, then add FP to SOS,        uses SOS internally
                                    then move (SOS) to GPL, then add 2 to SOS, then move (SOS) to GPH                           rrrrr is in the range: [0,31]
10100111010rrrrr    LOCAL-STORE21   move literal to GPL, then shift GPL left by two bits, then negate GPL, then add FP to GPL,
                                    then move TOS to (GPL), then move SOS to TOS                                                rrrrr is in the range: [0,31]
10100111011rrrrr    LOCAL-STORE     move literal to GPL, then shift GPL left by two bits, then negate GPL, then add FP to GPL,
                                    then move TOS to (GPL), then pop TOS                                                        rrrrr is in the range: [0,31]
10100111100rrrrr    ++LOCAL-FETCH   move literal to GPL, then shift GPL left by two bits, then negate GPL, then add FP to GPL,
                                    then move (GPL) to GPH, then add GPH to TOS, then move TOS to (GPL)                         rrrrr is in the range: [0,31]
10100111101vvvvv    DLSHR           logical shift right TOS into SOS by vvvvv bits (fill upper bits with 0)                     vvvvv is in the range: [0,31]
10100111110vvvvv    DLSHL           logical shift left  SOS into TOS by vvvvv bits (fill lower bits with 0)                     vvvvv is in the range: [0,31]
10100111111aaaaa    LIT-CSTORE      move literal to GPL, then move TOS to (GPL) 8-bit, then pop TOS                             aaaaa is in the range: [0,31]
10101000000aaaaa    LIT-STORE       move literal to GPL, then move TOS to (GPL) 16-bit, then pop TOS                            aaaaa is in the range: [0,31]
1010101rrrrrrrrr    LIT-IP-PLUS12   move TOS to SOS, then move literal to TOS, then add IP to TOS                           rrrrrrrrr is in the range: [-256,255]
1010110rrrrrrrrr    LIT-IP-PLUS     push TOS,        then move literal to TOS, then add IP to TOS                           rrrrrrrrr is in the range: [-256,255]
101011100vvvvvvv    NLIT12          move TOS to SOS, then move negative literal to TOS                                      vvvvvvvvv is in the range: [-128,0]
101011101vvvvvvv    NLIT            push TOS,        then move negative literal to TOS                                      vvvvvvvvv is in the range: [-128,0]
10101111vvvvvvvv    BLIT12          move TOS to SOS, then move literal to TOS                                               vvvvvvvvv is in the range: [0,255]
1011vvvvvvvvvvvv    BLIT            push TOS,        then move literal to TOS                                            vvvvvvvvvvvv is in the range: [0,4095]
11aaaaaaaaaaaaaa    CALL            push IP to the return-stack, then move literal to IP                               aaaaaaaaaaaaaa is in the range: [16384,32767]

The Stundurd is a little-endian processor, so for a 16-bit datum the low byte is first and the high byte is second (for a 32-bit datum, the low cell is first and the high cell is second). A double-precision integer (32-bit) on the parameter stack has the low cell in SOS and the high cell in TOS, the same as in ANS-Forth as well as every other Forth. The instructions are big-endian --- the high byte (the byte with the tag at the top) is first and the low byte (the operand) is second.

The low 32KB is non-volatile memory, and the high 32KB is RAM. Of the non-volatile, the CALL primitive can call any function in the upper 16KB. The lower 16KB can hold code, but it can only be accessed with EXECUTE or GOTO but not CALL. The quotations typically are in the lower 16KB, as well as constant data. The I/O ports are mapped into the low addresses of [0,31]. The reason why non-volatile memory is in the lower addresses and RAM is in the higher addresses (this is backwards from how most processors are arranged), is because our literal primitive BLIT only allows literal values up to 4095. If we want a literal value larger than this, then it has to be stored as a constant in non-volatile memory, and the address of the constant has to be in the range [0,4095] so BLIT can push the address for FETCH or DFETCH12 to use. Because of this, non-volatile memory is in the low addresses and all of the constants are in the low 4KB (except for the range [0,31] that is I/O).

Stundurd code tends to be heavily factored, so there are a lot of function calls in typical code. The CALL is a two-byte instruction, which is less than on most processors (it was three bytes on the Intel 8051, which was designed to have compact code). A primitive call is a one-byte instruction (there are 64 primitives total). BRANCH is a two-byte instruction, which is the same as for most processors (8051 etc.), however our branch is in the [-256,255] range rather than the [-128,127] range typical of mainstream processors, so there should never be an out-of-range error in a reasonably well-factored Stundurd program. We have "skippy" primitives, that conditionally skip over the next two bytes. A BRANCH is a two-byte instruction, so it can be put in the skip-area of a skippy primitive, effectively making conditional-branches three-byte instructions. We have a lot of one-byte and two-byte instructions though, so it is sometimes possible to put one or two instructions in the skip-area, which is more efficient than putting a BRANCH in the skip-area to go to those instructions elsewhere.

Literals are somewhat complicated. For a literal in the [0,31] range, we get by with a one-byte instruction. These small literals are quite common, so they were designed to be compact and fast. The I/O ports are memory-mapped in the [0,31] range, so the address of an I/O port can be pushed with SLIT12 or SLIT. Also, an I/O port can be stored into with LIT-CSTORE or LIT-STORE. Accessing I/O is a big part of what micro-controller programs do, so we want this to be compact and fast. Also, doing logical operations with the data going to and from the I/O ports is common, so we have LIT-AND, LIT-IOR and LIT-EOR to make that compact and fast. Accessing fields in a struct is important, so we have LIT-PLUS for that. Accessing locals is important, so we have LOCAL, LOCAL-STORE21, LOCAL-STORE and ++LOCAL-FETCH for that. We also have NLIT and NLIT12 for literals in the [-128,-1] range, BLIT12 for literals in the [32,255] range, and BLIT for literals in the [32,4095] range. NEG can be used after BLIT to provide literals in the [-4095,-129] range. A big part of what makes the Stundurd efficient, is that the a lot of literals are embedded in the opcode. For literals outside of these ranges, the value can be stored in a constant whose address is near the function containing the literal and obtain the address of the literal with LIT-PLUS-IP or LIT-PLUS-IP12 (it is a relative address either plus or minus from the IP, so it can be either ahead of or in front of the function). The literal can then be obtained with FETCH or DFETCH12. The programmer doesn't have to remember which instructions are used to generate literals in which ranges, as the assembler has the macros LIT12 and LIT that compile the correct instruction(s) for any particular literal value --- the programmer however does need to be able to figure out which instruction(s) are getting compiled for any particular literal, so he can know how many bytes LIT12 or LIT are taking up in the skip-area of the skippy primitives. Note that LIT-PLUS-IP was suggested by Bernd Linsel.

We have four regions for non-volatile memory: 
LREGION [32,255]
MREGION [256,4095]
FREGION [4096,16383]
HREGION [16384,32767]
Colon words are compiled into HREGION (the CALL primitive only has access to HREGION). Quotations are compiled into MREGION and their addresses are obtained with BLIT (this provides the cfa, then QXT12 is used to convert the cfa into an xt). Literals used in Forth words (or in assembly-language code that uses LIT12 or LIT) are compiled into HREGION adjacent to the function that accesses them and their address is obtained with LIT-PLUS-IP or LIT-PLUS-IP12. Constants defined with CONSTANT or DCONSTANT are compiled into LREGION, and if LREGION is full then MREGION is used instead. CREATE defines a constant (using CONSTANT internally) that is a pointer to the next available memory location in FREGION (comma compiles into FREGION). The :NONAME words are compiled in the FREGION. The SWITCH statement compiles an array in FREGION that contains pointers to code that is also compiled in FREGION. For the most part, the Forth programmer doesn't have to worry about what regions are being used for what, but he just ignores the whole issue and hopes that no region overflows. If HREGION overflows, this means that the colon words are too big --- the programmer can rewrite some of his colon words to be defined with FAR: rather than : --- this causes the code to be compiled into FREGION rather than HREGION at a slight cost in speed in calling the word (execution of the colon word is the same speed though). If MREGION overflows, this means that the quotations are too big --- some of the quotations should be factored so they call colon words rather than just have all the code inline. If FREGION overflows, this means that the arrays of constant arrays (defined with CREATE) are too big --- the programmer should upgrade to a 32-bit processor such as the ARM, as the Stundurd doesn't provide anywhere other than FREGION to put this constant data.

In assembly language, we have these directives:
LLABEL causes compilation to be in LREGION (low region)
MLABEL causes compilation to be in MREGION (medium region)
FLABEL causes compilation to be in FREGION (far region)
HLABEL causes compilation to be in HREGION (high region)
LABEL  same as HLABEL (this is generally used for everything)
Normally LABEL is used for code, and for constant data, and also for jump tables used by GOTO (it is used for everything). Sometimes LLABEL or MLABEL have to be used for a constant datum because the datum is used by multiple functions and it isn't in range of LIT-PLUS-IP or LIT-PLUS-IP12 for all of them. MLABEL can be used for jump-tables for GOTO if HREGION is in danger of filling up --- FLABEL could be used for jump-tables if they are gigantic, but this is somewhat cumbersome (the programmer has to manually define a constant with LLABEL or MLABEL containing a pointer to the jump-table and fetch from the pointer to obtain the actual address of the jump-table). For the most part, assembly-language programmers should just use LABEL and not worry --- it would be rare that this doesn't work.

RAM is much simpler than non-volatile. There are no regions; everything in [$8000,$ffff] is RAM. The parameter stack is at [$8000,$80FE] and the return-stack is at [$8100,$81FE]. Global variables start at $8200 and go up; these are defined at compile-time. ALLOT allots memory in RAM. RHERE is like HERE in ANS-Forth but is for RAM. FHERE is for FREGION and is constant data. We have <BUILDS DOES> for traditional defining words. When the DOES> code executes, the FHERE value at the time of the <BUILDS is pushed onto the return-stack. Comma advances FHERE. If the programmer wants some RAM, he can comma RHERE into a field and then ALLOT to make room for whatever he needs. We also have generators (the term is borrowed from the Icon language). These are colon words that are defined with TSR: rather than : and they allocate their local-frame in the heap rather than on the return-stack. TSR means "Terminate and Stay Resident" --- this is because the local-frame stays valid after the TSR has exited (unlike a regular colon word whose local-frame becomes invalid when it exits). The idea is that the TSR returns a quotation xt and this quotation has access to the local-frame indefinitely. TSRs are discussed further in section 16.5.. In some cases they can be used instead of <BUILDS DOES> words with the generator being like the DOES> code --- generators are different from <BUILDS DOES> definers because they build their struct at run-time rather than compile-time and they put it in the heap rather than the dictionary, and they also don't have names in the dictionary --- TSRs can do everything that <BUILDS DOES> words do and better, so they are the idiom in Stundurd Forth, with <BUILDS DOES> provided mostly to support legacy Forth code (in ANS-Forth it is called CREATE DOES> but that is easy to port over).

Here is a simple example of a colon word:

: false-double  \ n flag -- new-n
    0= if  dup +  then ;

This would get compiled like this:
s" false-double" header21
    PUFF21
s" false-double" header
    ZERO?  DUP12  PLUS21  ??
    RETURN

Both DUP12 and PLUS21 are one-byte instructions, so we can have the two of them get skipped over together by our ZERO? instruction.

As another example, consider this:

: maybe-boop  \ flag --
    if  boop  then ;                \ BOOP is a colon word

This could get compiled like this:
s" maybe-boop" header21
    puff21
s" maybe-boop" header
    ZERO?  label:1 BRANCH  ??       \ this is like 0BRANCH in a classical Forth
    ' BOOP CALL
1 label
    RETURN

The ZERO? is a skippy instruction. It tests TOS (and consumes TOS) and skips over the next two bytes if TOS was zero.  The ?? brackets the skip area (it is a double ?? to remind the programmer that there are two bytes in the skip area). The ?? will abort with an error if more or less than two bytes have been compiled into the machine-code after the skippy primitive (this sometimes happens when the assembly-language programmer can't remember if he is using a primitive or a macro, or how many bytes of code a particular macro generates).

A more efficient compilation would be this:
s" maybe-boop" header21
    puff21
s" maybe-boop" header
    ZERO?  RETURN  NOP  ??          \ both RETURN and NOP are one-byte instructions; we need the NOP to fill out the two-byte skip area
    ' BOOP CALL
    RETURN

If only 1 one-byte primitive needs to be skipped, the two-byte skip-area should be padded with a NOP primitive.

A yet more efficient compilation would be this:
s" maybe-boop" header21
    PUFF21
s" maybe-boop" header
    ZERO?  RETURN  NOP  ??
    ' BOOP BRANCH

This is called "tail-call optimization" (in ISYS Forth on the Apple-II, it was called "jump termination"). The advantage is that it is more efficient, and it doesn't put anything on the return-stack so there is less chance of the return-stack overflowing (especially in a mutually recursive call). This is only going to work if the other function is quite close (in the [-512,511] range). Sometimes this works out with mutually recursive functions allowing great efficiency, but the functions are usually too far apart for this to work out. For reasons obscure, Scheme programmers use self-recursion to do iteration, rather than use BEGIN WHILE REPEAT which is idiomatic in Stundurd --- recursion-as-iteration can be done in Stundurd, and the [-256,255] range of BRANCH should always be adequate. Considering how compact Stundurd code is, no function should be anywhere near 256 bytes in size --- it is idiomatic in Stundurd, Forth, Factor, Scheme, etc. (but not in C, Pascal etc.) to factor a big function down into small functions.

This is an efficient compilation that will work out every time.
s" maybe-boop" header21
    PUFF21
s" maybe-boop" header
    NONZERO?  ' BOOP CALL  ??
    RETURN


section 3.) an introductory discussion of huffing and puffing

The huffers and puffers have a two-digit numeric suffix on the name to indicate how many data are in registers before and after. If the suffix would be 11, then the suffix is not needed because this is the default configuration.

For example, here is the OVER ( a b -- a b a ) function:
s" over" header     \ this is our nominal version that starts with TOS valid and the rest of the stack in memory
    HUFF12          \ we have to huff the second value into SOS in preparation for OVER22
s" over" header21   \ this is our faster version that starts with TOS and SOS valid and the rest of the stack in memory
    OVER22          \ this primitive expects 2 values to be in registers (SOS and TOS), and it leaves 2 values in registers (SOS and TOS)
    PUFF21          \ functions always end with TOS valid and the rest of the stack in memory, so we have to puff the second value (SOS) to memory
    RETURN

There is no OVER primitive --- we have only OVER22 available --- so we needed to do some huffing and puffing in our function above. We have two versions of the OVER function. The nominal version is defined with HEADER and assumes only TOS valid. The xt contains the cfa of this version, so EXECUTE executes this version. We also have a faster version that assumes TOS and SOS are valid (and hence doesn't have to huff SOS in from memory). The cross-compiler will compile a CALL21 to the faster version if it notices that TOS and SOS are both valid prior to the call. If only TOS is valid prior to the call, then it will compile a CALL to the slower version that assumes only TOS is valid. CALL21 and CALL are actually the same primitive; the difference is which version of the function that they call.

As another example, here is the NEGATE ( a -- -a ) function:
s" negate" header21
    PUFF21
s" negate" header
    NEG         \ the NEG primitive could be called NEG11, but this is the default configuration so we don't bother with the 11 suffix
    RETURN

We also have the macro NEG22 that is equivalent to the NEG primitive, because NEG works whether the second value is in register or in memory --- this macro helps to improve the readability of the assembly-language code, as the reader is reminded of how many values are in registers.

Some pseudo-primitives are implemented as macros. As an example, the TUCK22 macro is:
    SWAP22
    OVER22
At one time, during the course of designing the Stundurd, TUCK22 was a primitive. TUCK isn't used very much in typical Stundurd programming though, so it got demoted to being a macro. The programmer has to be careful to remember that TUCK22 is a macro, not a primitive, so he doesn't make this mistake:
    ZERO?  TUCK22  NOP  ??      \ the ?? will abort because three bytes got compiled
That should be:
    ZERO?  TUCK22  ??           \ this is legal because two bytes got compiled
The skippy primitives always skip over two bytes --- either 1 two-byte primitive, or 2 one-byte primitives (SWAP22 and OVER22 in our example).

More will be said on the subject of huffing and puffing later in section-8 of this article.


section 4.) the primitives (this is the section that readers will reference again and again)

There are 64 primitives:

\ (20) stack juggling
HUFF01      pull TOS                                                                                    the optimizer strives to minimize the use of this
HUFF12      pull SOS                                                                                    the optimizer strives to minimize the use of this
PUFF21      push SOS                                                                                    the optimizer strives to minimize the use of this
>GP21       move SOS:TOS to GPL:GPH, then pull TOS
GP12        push TOS, then move GPL:GPH to SOS:TOS
DUP         push SOS, then move TOS to SOS
DUP12       move TOS to SOS
DROP21      move SOS to TOS
SWAP12      move TOS to SOS, then pull TOS
SWAP22      exchange SOS and TOS
OVER22      exchange SOS and TOS, then push TOS
ROT22       pull GPL, then push SOS, then move TOS to SOS, then move GPL to TOS                         uses GPL internally
-ROT22      pull GPL, then push TOS, then move SOS to TOS, then move GPL to SOS                         uses GPL internally
ROVER22     move SOS:TOS to GPL:GPH, then move (PS) to TOS, then push GPL, then move GPH to SOS         uses GPL:GPH internally     like OVER22 but for the 3rd item
RDROP       add 2 to RS
TOR         push TOS to return-stack, then pull TOS
TOR21       push TOS to return-stack, then move SOS to TOS
RFROM       push TOS, then pull TOS from return-stack
RFROM12     move TOS to SOS, then pull TOS from return-stack
RFETCH12    move TOS to SOS, then move (RS) to TOS

\ (23) control flow
NOP         do nothing                                                                                  used as padding in the skip-area of DUP-NONZERO? etc.
GOTO        move TOS to IP, then pop TOS                                                                used for jump-tables
LINK        push FP to the return-stack, then move RS to FP                                             used at start of colon words
UNLINK      move FP to RS, then pull FP from return-stack, then pull IP from return-stack               used at the end of colon words instead of RETURN
INIT-LOCAL  sign-extend TOS into GPH, then push GPH to return-stack, then push TOS to return-stack, then pull TOS           uses GPH        used after LINK
2INIT-LOCAL21   sign-extend TOS into GPH, then push GPH to return-stack, then push TOS to return-stack, then
                sign-extend SOS into GPL, then push GPL to return-stack, then push SOS to return-stack, then pop TOS        uses GPL:GPH    used after LINK
DINIT-LOCAL21   push SOS to return-stack, then push TOS to return-stack                                                                     used after LINK
ZERO-LOCAL  move zero to GPL, then push GPL to return-stack, then push GPL to return-stack                                  uses GPL        used after LINK
LOCAL       logical shift TOS left by two bits, then negate TOS, then add FP to TOS
QLINK       push FP to the return-stack, then move GPH to FP                                            used at start of quotations
QUNLINK     pull FP from return-stack, then pull IP from return-stack                                   used at the end of quotations instead of RETURN
RETURN      pull IP from return-stack
RETURN-ISR  pull GPL GPH SOS TOS and IP from return-stack                                               we either have SLEEP or RETURN-ISR but not both
SLEEP       put the core into a low-power sleep mode until it gets woken up again by the hardware       we either have SLEEP or RETURN-ISR but not both
QXT12       move TOS to SOS, then move FP to TOS
EXECUTE-GP  push IP to return-stack, then move GPL to IP                                                GPH is available for QLINK if this is a quotation
DUP-ZERO?       if TOS<>0  add 2 to IP                                                                  skip over 2 one-byte instructions, or 1 two-byte instruction
DUP-NONZERO?    if TOS=0   add 2 to IP                                                                  skip over 2 one-byte instructions, or 1 two-byte instruction
ZERO?           if TOS<>0  add 2 to IP, then pull TOS                                                   skip over 2 one-byte instructions, or 1 two-byte instruction
NONZERO?        if TOS=0   add 2 to IP, then pull TOS                                                   skip over 2 one-byte instructions, or 1 two-byte instruction
NEG?            if TOS>=0  add 2 to IP, then pull TOS                                                   skip over 2 one-byte instructions, or 1 two-byte instruction
NONNEG?         if TOS<0   add 2 to IP, then pull TOS                                                   skip over 2 one-byte instructions, or 1 two-byte instruction
POS?            if TOS<=0  add 2 to IP, then pull TOS                                                   skip over 2 one-byte instructions, or 1 two-byte instruction
RFROM-LOOP?     push TOS, then pull TOS from return-stack, then decrement TOS, then                     same as: RFROM DEC DUP-NONZERO?    used in |ITERATE and |UNTIL
                if TOS=0   add 2 to IP                                                                  skip over 2 one-byte instructions, or 1 two-byte instruction

\ (9) memory access
FETCH       move (TOS) to TOS
CFETCH      move (TOS) to TOS; 8-bit unsigned
DFETCH12    move TOS to GPL, then move (GPL) to SOS, then add 2 to GPL, then move (GPL) to TOS          uses GPL internally
PLUS-STORE21    move (TOS) to GPL, then add GPL to SOS, then move SOS to (TOS), then pull TOS           uses GPL internally
STORE21     move SOS to (TOS), then pull TOS
CSTORE21    move SOS to (TOS); 8-bit unsigned, then pull TOS
DSTORE21    move TOS to GPL, then add 2 to GPL, then move SOS to (GPL), then
            pull GPH, then move GPH to (TOS), then pull TOS                                             uses GPL:GPH internally
WEXCH-GP    needs GPL= source-address, GPH = destination-address, TOS = count,                          sets SOS to value read from (GPL)
            move (GPH) to SOS,
            then exclusive-or SOS into (GPL), then exclusive-or (GPL) into SOS, then exclusive-or SOS into (GPL)
            then move SOS to (GPH), then add 2 to GPL, then add 2 to GPH, then subtract 2 from TOS
WMOVE-GP    needs GPL= source-address, GPH = destination-address, TOS = count,                          sets SOS to value moved
            move (GPL) to SOS, then move SOS to (GPH); 16-bit
            then add 2 to GPL, then add 2 to GPH, then subtract 2 from TOS

\ (3) logic
AND21       logical and SOS to TOS
IOR21       logical inclusive-or SOS to TOS
EOR21       logical exclusive-or SOS to TOS

\ (4) addition and subtraction
ASHR        shift TOS right by one bit, fill bit-15 with original bit-15 of TOS (upper bit is "sticky")
NEG         negate TOS
PLUS21      add SOS to TOS
MINUS21     negate TOS, then add SOS to TOS

\ (3) multiplication and division
SIGN22      set GPL to eor(SOS,TOS), then push GPL, then set SOS to |SOS|, then set TOS to |TOS|        uses GPL internally
UMULT22     unsigned multiply SOS by TOS, store result in GPL:GPH, then move GPL:GPH to SOS:TOS
UDIV12      unsigned divide GPL:GPH by TOS, store the remainder in SOS and the quotient in TOS

\ (2) double-precision arithmetic
DNEG22      negate SOS:TOS
DPLUS22     add GPL:GPH to SOS:TOS


section 5.) common macros

There are only 64 primitives. We have macros to make up for the shortfall however. These compile to typically a couple of primitives. In a classical Forth that doesn't have any limit on the number of primitives (other than the implementer's diligence in writing them), these would have been primitives too.

DROP                =   HUFF01
DDROP21             =   HUFF01
3DROP21             =   DDROP21 DROP
SWAP                =   SWAP12 PUFF21
ROT                 =   HUFF12 ROT22 PUFF21
NIP                 =   HUFF12
NIP21               =   assembles to nothing
NIP22               =   HUFF12
RIP22               =   >GP21 DROP GP12                                 uses GPL:GPH internally         like NIP22 but for the 3rd item
TUCK12              =   SWAP12 OVER22
TUCK22              =   SWAP22 OVER22
RUCK22              =   -ROT22 ROVER22                                  uses GPL:GPH internally         like TUCK22 but under the 3rd item
OVER-PLUS22         =   PLUS21
TRUE                =   1 SLIT                                                                          returns a proper flag of TRUE(1)
TRUE12              =   1 SLIT12                                                                        returns a proper flag of TRUE(1)
FALSE               =   0 SLIT                                                                          returns a proper flag of FALSE(0)
FALSE12             =   0 SLIT12                                                                        returns a proper flag of FALSE(0)
RFETCH              =   RFETCH12 PUFF21                                                                 for the top value on the return-stack
RRFETCH             =   RFROM RFROM12 SWAP22 TOR21                                                      for the second value on the return-stack
DRFETCH12           =   RFROM RFROM12                                                                   does not swap the data, as 2R@ in ANS-Forth does
RSTORE              =   RDROP TOR
RSTORE21            =   RDROP TOR21
INC                 =   1 LIT-PLUS
INC22               =   INC
DEC                 =   -1 LIT-PLUS
DEC22               =   DEC
WINC                =   2 LIT-PLUS
WINC22              =   WINC
DINC                =   4 LIT-PLUS
DINC22              =   DINC
WDEC                =   -2 LIT-PLUS
DDEC                =   -4 LIT-PLUS
DDEC22              =   DDEC
FETCH22             =   FETCH
CFETCH22            =   CFETCH
HFETCH              =   WINC FETCH                                                                      fetch the high-cell of a double-cell value
HFETCH22            =   WINC FETCH
DFETCH              =   DFETCH12 PUFF21
PLUS-STORE          =   HUFF12 PLUS-STORE21
STORE               =   HUFF12 STORE21
CSTORE              =   HUFF12 CSTORE21
DSTORE              =   HUFF12 DSTORE21
AND                 =   HUFF12 AND21
IOR                 =   HUFF12 IOR21
EOR                 =   HUFF12 EOR21
NOT                 =   1 LIT-EOR                                                                       expects a proper flag of TRUE(1) or FALSE(0)
FLG-NONZERO22       =   DUP-NONZERO?  DROP21  TRUE12  ??                                                returns a proper flag of TRUE(1) or FALSE(0)
FLG-ZERO22          =   DUP-NONZERO?  DROP21  TRUE12  ??  NOT                                           returns a proper flag of TRUE(1) or FALSE(0)
FLG-NONZERO         =   FLG-NONZERO22                                                                   returns a proper flag of TRUE(1) or FALSE(0)
FLG-ZERO            =   FLG-ZERO22                                                                      returns a proper flag of TRUE(1) or FALSE(0)
FLG-ZERO-LT         =   15 LSHR                                                                         returns a proper flag of TRUE(1) or FALSE(0)
FLG-ZERO-GTE        =   15 LSHR  NOT                                                                    returns a proper flag of TRUE(1) or FALSE(0)
FLG-ZERO-LT22       =   FLG-ZERO-LT                                                                     returns a proper flag of TRUE(1) or FALSE(0)
FLG-ZERO-GTE22      =   FLG-ZERO-GTE                                                                    returns a proper flag of TRUE(1) or FALSE(0)
NOT22               =   NOT
ASHL                =   1 LSHL
ASHL22              =   1 LSHL
ASHR22              =   ASHR
NEG22               =   NEG
PLUS                =   HUFF12 PLUS21
MINUS               =   HUFF12 MINUS21
ABS                 =   DUP  NEG?  NEG  NOP  ??
DNEG                =   HUFF12 DNEG22 PUFF21
DPLUS               =   HUFF12 DPLUS22 PUFF21
?DUP                =   DUP-ZERO?  DUP12 PUFF21  ??
DDUP22              =   OVER22 OVER22

FLG-NONZERO and FLG-ZERO use DROP21 and TRUE12 despite the fact that there is no valid value in SOS. This is faster than using DROP and TRUE which are nominally correct, but which move the actual second-on-stack value in from memory to TOS and then back out to memory again. This is a good trick to keep in mind anytime that DROP is followed by a primitive that pushes a value (effectively replacing the old value) --- use DROP21 and xxx12 for speed, as this avoids memory access.

ANS-Forth defines these words:

2>R  \ a b --       \ return stack: -- a b          \ effectively the same as: SWAP >R >R
2R>  \ -- a b       \ return stack: a b --          \ effectively the same as: R> R> SWAP
2R@  \ -- a b       \ return stack: a b -- a b      \ effectively the same as: R> R>  2DUP >R >R  SWAP

These words are very confusing because they swap the data internally. If two data are pushed to the return-stack with >R >R then 2R> or 2R@ will put them back on the data-stack in the opposite order that they were previously. This was done so that, after 2>R are used to push a double-integer to the return-stack, R@ can be used to obtain the high-cell which is where the sign bit is --- this is presumably the purpose of the internal swapping anyway --- the ANS-Forth document doesn't offer any justification for the internal swapping so we can only guess as to what they were thinking (or smoking).

In Stundurd we do not have 2>R or 2R> at all. The programmer should use >R >R to push two data to the return-stack, and R> R> to pull two data from the return-stack. We do have these words:

DR@  \ -- a b       \ return stack: b a -- b a      \ does not swap the data like the 2R@ in ANS-Forth
R@  \ -- a          \ return stack: b a -- b a      \ the same as R@ in ANS-Forth; returns the top value of the return-stack
RR@  \ -- b         \ return stack: b a -- b a      \ not available in ANS-Forth; returns the second value of the return-stack

This is much more straight-forward than ANS-Forth. Programmers accustomed to ANS-Forth may be confused by 2R@ working differently --- fortunately however, there aren't very many ANS-Forth programmers in the world (and most of them are perpetually confused anyway) --- if a Stundurd programmer pushes a double-integer to the return-stack with >R >R then he can use use RR@ to obtain the high-cell where the sign bit is.

In ANS-Forth, and every other Forth, words that work with two datums have a '2' prefix. In Stundurd, all of these words will have a 'D' prefix. For example, instead of 2R@ 2DUP 2OVER etc., we will have DR@ DDUP DOVER etc.. This was Michael Barry's suggestion.


section 6.) local variables

Local variables are defined with LOCAL{ in Stundurd. This is rather than with { as has been done in Forth for 20+ years, or by {: as is done in Forth-200x now.

Here is an example:

: m+  local{ :d s -- :sum }     \ in the LOCAL{ declaration, a colon anywhere in a parameter name indicates that it is a double-cell value
    s d@  :d d@  d+ ;

Everything after the -- in the LOCAL{ } definition is a comment and is ignored. As a convention, this shows what data is left on the data-stack after the function finishes (in this case, the count value).

The M+ local{ :d s -- :sum } function could compile like this:
s" m+" header21
    PUFF21
s" m+" header
    LINK
    INIT-LOCAL                  \ automatically sign-extends the single into a double
    HUFF12
    DINIT-LOCAL21               \ the double in SOS and TOS goes into the local
    1 LIT
    LOCAL                       \ this is S
    DFETCH12
    >GP21
    2 LIT
    LOCAL                       \ this is :D
    DFETCH12
    DPLUS22
    PUFF21
    UNLINK

INIT-LOCAL initializes a single-cell value, automatically sign-extending it into a double-cell local. DINIT-LOCAL21 initializes a double-cell value into a double-cell local. Any local variable with a colon somewhere in the name is assumed to be a double-cell value. All locals are double-cell whether they were initialized from a single-cell value by INIT-LOCAL or were initialized from a double-cell value by DINIT-LOCAL21. LOCAL is given an index to the local, and it returns the address of the local. The index corresponds to the order that the local was initialized. Here, the index to S is 1 because it was initialized first, and the index to :D is 2 because it was initialized second. This is the opposite order from how the locals were defined inside of LOCAL{ }.

For numeric doubles, the colon would go on the front of the parameter name (as shown above with :D and :SUM in the M+ function). For pairs of singles that are treated like a double, the colon would go in the middle. The most common example is ADR:CNT that represents a string. Using this naming convention improves the readability of the Stundurd source-code a lot. Most Forth programs just put ADR and CNT in the stack-picture without any indication that they are related to each other.

Locals can be efficient and can improve readability in cases in which there are more than three parameters, as they reduce stack-juggling. When there are only a few parameters it may be more efficient to not use locals. For example:

: m+  \ :d s -- :sum            \ the convention in stack pictures is that a colon anywhere in a parameter name indicates that it is a double-cell
    s>d  d+ ;

This compiles as:
s" m+" header21
    PUFF21
s" m+" header
    ' S>D CALL
    HUFF12
    >GP21
    HUFF12
    DPLUS22
    PUFF21
    RETURN

Here is another example:

: distance  local{ ax ay bx by -- distance }
    ax @ bx @ -  dup m*
    ay @ by @ -  dup m*
    d+  msqrt ;

This compiles like this
s" distance" header
    HUFF12
s" distance" header21
    LINK
    2INIT-LOCAL21               \ initializes BY (TOS) then BX (SOS)
    INIT-LOCAL                  \ initializes AY (TOS)
    INIT-LOCAL                  \ initializes AX (TOS)
    1 LIT
    LOCAL                       \ this is AX
    FETCH
    3 LIT12
    LOCAL                       \ this is BX
    FETCH22
    MINUS21
    DUP12
    ' M* CALL21
    2 LIT
    LOCAL                       \ this is AY
    FETCH
    4 LIT12
    LOCAL                       \ this is BY
    FETCH22
    MINUS21
    DUP12
    ' M* CALL21
    HUFF12
    >GP21
    HUFF12
    DPLUS22
    ' MSQRT CALL21
    UNLINK

2INIT-LOCAL21 initializes two single-cell locals which are in SOS and TOS. This is not the same as DINIT-LOCAL21 that initializes one double-cell local that is in SOS and TOS. 2INIT-LOCAL21 makes the code more efficient when there are a lot of single-cell locals. If we didn't have the 2INIT-LOCAL21 primitive then the case of the calling function already having SOS and TOS valid would be two instructions longer, both of which involve a memory access, which is much less efficient:
s" distance" header21
    PUFF21
s" distance" header
    LINK
    INIT-LOCAL                  \ initializes BY (TOS)
    INIT-LOCAL                  \ initializes BX (TOS)
    INIT-LOCAL                  \ initializes AY (TOS)
    INIT-LOCAL                  \ initializes AX (TOS)
    ...

Actually, functions like DISTANCE that have a lot of parameters are generally badly designed. Here is a more efficient and more readable alternative:

0
    w field .x
    w field .y
constant point

0
    point field .a
    point field .b
constant line

: line.length  \ ^line -- length            \ ^line is a pointer to a line object (the caret is a naming convention for pointers, like in Pascal)
    >r
    r@ .a .x @  r@ .b .x @  -  dup m*
    r@ .a .y @  r@ .b .y @  -  dup m*
    d+  msqrt ;

This compiles like this:
s" line.length" header21
    PUFF21
s" line.length" header
    LINK
    DUP12
    TOR21
    FETCH                   \ R@ .A .X @
    RFETCH12
    .b .x LIT-PLUS
    FETCH22                 \ R@ .B .X @
    MINUS21
    DUP12
    ' M* CALL21
    RFETCH
    .a .y + LIT-PLUS
    FETCH                   \ R@ .A .X @
    RFETCH12
    .b .y + LIT-PLUS
    FETCH22                 \ R@ .B .Y @
    MINUS21
    DUP12
    ' M* CALL21
    HUFF12
    >GP21
    HUFF12
    DPLUS22
    ' MSQRT CALL21
    UNLINK

So far, we have seen only locals that were initialized from the data-stack (both single-cell and double-cell). It is also possible to have locals that are initialized to zero. These are defined after the bar character. Here is an example:

: length  local{ head | count -- count }
    head @  begin  dup while  1 count +!  .fore @  repeat drop
    count @ ;

This function calculates how many nodes are in a linked list. We are assuming that the first node in the list is .FORE that contains the link pointer.

This is how it compiles:
s" length" header21
    PUFF21
s" length" header
    DUP-ZERO?  RETURN  NOP  ??
    LINK
    ZERO-LOCAL          \ this initializes our COUNT local
    INIT-LOCAL          \ this initializes our HEAD local
    1 LIT
    LOCAL               \ this is HEAD
    FETCH
    ZERO?  label:2 BRANCH  ??
1 label
    2 ++LOCAL-FETCH22   \ this is COUNT
    DROP21              \ we don't need to keep the result
    FETCH               \ get next node
    DUP-NONZERO?  label:1 BRANCH  ??
2 label
    2 LIT12
    LOCAL12             \ this is COUNT
    FETCH22
    NIP21
    RETURN

The COUNT local is the first local initialized (by ZERO-LOCAL), so it gets an index of 1. ZERO-LOCAL does not pull any data off the data-stack, but it just initializes the local to zero.


section 7.) quotations (a kind of lambda function)

Stundurd Forth supports quotations, which are a kind of lambda functions. A quotation is an anonymous function nested within another function. Its xt can be passed as a parameter into a sub-function (called a "higher-order function") and executed with EXECUTE. When the quotation executes, it has access to the local variables of the parent function (the function that it was defined within). A quotation can't have any local variables of its own; if it needs local variables, they have to be defined in the parent function. It is illegal to execute the xt of a quotation after the parent function has gone out of scope (done its EXIT). This will fail badly if the quotation is accessing the parent function's local variables, because that local-frame no longer exists and that memory is likely being used by some other function's local variables and/or return-address (it will seem to work, but some other code will stop working because its local data has been clobbered, which is a difficult bug to track down). If the quotation is not accessing the parent function's local variables, it will actually work without any harm --- this is still considered to be illegal (or, at least, bad style) because the quotation should be dead (like a person without a soul), so it is confusing for it to still be live --- as always, :NONAME is used to define anonymous functions that don't have a parent and remain valid indefinitely (:NONAME isn't very useful). Preventing quotations from executing after their parent function has gone out of scope, is discussed in section-16 of this article.

Locals are defined with LOCAL{ and quotations are defined with { in Stundurd Forth. Here is an example:

list
    d field .name$      \ employee name
    d field .salary     \ salary per year in dollars
    c field .female?    \ flag indicating gender
constant employee

: count-females  local{ employee-head | cnt -- females }     \ EMPLOYEE-HEAD is the head of a LIST linked list
    employee-head @  { .female? c@  cnt +! }  |each
    cnt @ ;

FIELD is used for defining a struct field (this isn't in ANS-Forth, but it has been well-known since prior to ANS-Forth.  Weirdly enough the name was changed to +FIELD in Forth-200x (the Forth-200x committee seem to have zero concern for supporting legacy code except for Forth Inc. legacy code). FIELD is in the novice-package for the reader who is unfamiliar with it. As a convention (for me, at least), field names always have a dot prefix; this is reminiscent of Pascal syntax (the term "struct" comes from C, whereas the term "record" was used in Pascal). When the field name is used, it generates code that adds an offset to an address. In the EMPLOYEE struct, the .NAME$ field has an offset of zero, so .NAME$ doesn't generate any code (there is no need to add zero to an address, but the address of the struct is already the address of the first field). The .SALARY field has an offset of 4 (because the previous field was 4 bytes in size), and so it adds 4 to the address. The .FEMALE? field has an address of 8 (because the previous fields were 8 bytes in size total), and so it adds 8 to the address. The .FEMALE? field has a size of 1, so the size of the entire struct is 9, and this is the constant EMPLOYEE. We have constants C (1), W (2) and D (4) that represent the size of chars, words (normally called "cells") and doubles respectively.

First we define a struct and make it a child of LIST (defined elsewhere). There are some other words that need to be written when defining a struct of a particular data-type (INIT-EMPLOYEE NEW-EMPLOYEE KILL-EMPLOYEE and CLONE-EMPLOYEE), but these won't be provided here because they aren't necessary for our discussion of quotations. Note that strings are always stored as a double-cell of address and count (we don't have counted strings, as produced by C" in ANS-Forth).

The function COUNT-FEMALES is given a pointer to a list of EMPLOYEE structs. The LOCAL{ ... } code defines the locals. All locals are big enough to hold either a single-cell or a double-cell value. The locals to the left of the | are initialized from the stack, with the right-most local being initialized from the top value of the stack. These single-cell values are sign-extended and stored in the locals as double-cell values. Because the Stundurd is little-endian, the address of the local points to either a valid single-cell value or a valid double-cell value. The locals to the right of the | are initialized to zero (this is unlike in Forth-200x in which the locals to the right of the | are initialized to whatever garbage value happened to already be in memory). When a local is executed, it returns the address of the local (Stundurd doesn't have the cruftastrophe known as TO that ANS-Forth foisted upon an innocent Forth community).

The { ... } code is the quotation. This is an anonymous nested function. After the } we get the xt of the quotation on the stack at run-time (QXT12 follows a LIT of the cfa and converts the cfa into an xt). In Stundurd, all xt values are double-cell (the top value is the cfa and the second value is the pointer to the local-frame for a quotation or zero for a colon word). In Stundurd, all functions are colon words; we don't have other kinds of functions (the definers CONSTANT CREATE and <BUILDS all generate colon words).

|EACH is defined elsewhere. This is a higher-order function with this stack-picture: ( head :xt -- ). EACH traverses the linked-list pointed to by HEAD, and it executes the XT for every node, giving that function the pointer to the node as a parameter. HEAD must point to a struct that was defined as a child-type of the LIST data-type. EMPLOYEE was defined as a child-type of LIST because it started with LIST (the size of the LIST data-type) as its base size, and so it inherited all of the fields of the LIST data-type.

When the quotation executes, it fetches the FEMALE? flag (in Stundurd, flags are 1 or 0 for true or false, rather than -1 or 0 as in ANS-Forth). It then adds this flag to the CNT local variable in the parent function (note that CNT was initialized to zero because it was defined to the right of the | marker). After EACH returns, the CNT local variable contains a count of how many female employees there were, so COUNT-FEMALES returns this value.

The primary purpose of providing quotations in Stundurd is so that general-purpose data-structures can be implemented. The above example is pretty typical. The programmer has linked-lists already provided to him. He can use them without knowing how they were implemented, or even having the source-code. Also, iteration gets hidden inside of higher-order functions, which makes the application program's source-code easier to read (and easier to write, because being easier to read results in fewer bugs) --- as a general rule, iteration is what confuses programmers the most when they are writing code.

This is how the COUNT-FEMALES colon word gets compiled:
s" count-females" header21
    PUFF21
s" count-females" header
    LINK
    ZERO-LOCAL      \ this initializes CNT
    INIT-LOCAL      \ this initializes EMPLOYEE-HEAD
    1 LIT
    LOCAL           \ this is EMPLOYEE-HEAD (it was the 2nd local-variable defined)
    FETCH
    aaa LIT         \ aaa is the cfa of our quotation
    QXT12           \ convert the quotation-cfa into an xt
    ' EACH CALL21   \ call the EACH colon word (it is a higher-order function, in so much as it takes an xt as a parameter and executes it)
    2 LIT
    LOCAL           \ this is CNT (it was the 1st local-variable defined)
    FETCH
    UNLINK

This is how the quotation in our example gets compiled:
    QLINK
    .female? LIT-PLUS
    CFETCH
    2 LIT12
    LOCAL           \ this is CNT (it was the 1st local-variable defined)
    PLUS-STORE21
    QUNLINK

The quotation could also be compiled like this:
    QLINK
    .female? LIT-PLUS
    CFETCH
    2 ++LOCAL-FETCH
    DROP            \ we don't need to keep the result (the new value of CNT)
    QUNLINK

When a function has LINK at the beginning, it should end with UNLINK rather than RETURN. Similarly, when a quotation has QLINK at the beginning, it should end with QUNLINK rather than RETURN. If the quotation doesn't access the local variables of the parent function, then the QLINK and QUNLINK are optional.

The index of the local variable, which is given to LOCAL, is the order that the locals were defined by INIT-LOCAL or ZERO-LOCAL. We have two local variables, which are EMPLOYEE-HEAD and CNT (everything past the -- is just a comment). The CNT local-variable has an index of 1, and the EMPLOYEE-HEAD local-variable has an index of 2. SLIT or SLIT12 are used to provide the index, so there can be as many as 31 local variables in a function (there is no local index of 0) --- 31 locals is way more than anybody would ever need.

UNLINK restores RS (the return-stack pointer) in preparation for RETURN. If there have been some >R done during the course of the function, it is not necessary to RDROP all of them at the end of the function --- that extraneous data can be left on the return-stack and UNLINK will get rid of it automatically. This is not true of QUNLINK however --- in quotations it is necessary to have an R> or RDROP corresponding to every >R done.

More will also be said about lambda functions and higher-order functions later in sections 12 through 16 of this article.


section 8.) more on huffing and puffing

The term "optimization" is a misnomer, because the code is only improved, not optimized. In this article we will use the term: "huffing and puffing." The idea is that data can be "huffed" (pulled from the stack into registers), operated on, and then "puffed" (pushed to the stack). The goal is to minimize the inefficient business of pushing a datum from a register to the stack, then immediately pulling that same data from the stack to that same register.

In many cases, huffing and puffing is a non-issue. For example:

s" warning-on" header21
    PUFF21
s" warning-on" header
    PortA LIT
    CFETCH
    %01000000 LIT-IOR
    PortA LIT-CSTORE
    RETURN

Throughout this function, we always have exactly one datum on the parameter stack. All of the literal values, such as PortA (the address of the port) and %01000000 (the bit mask), are embedded within the opcode that uses them and so they never get pushed onto the stack. All I/O ports are memory-mapped in the address range [0,31], so we can use fast instructions to access them (above, LIT compiled as SLIT that is fast, and LIT-CSTORE is another fast one) --- this is important in a micro-controller, because accessing I/O ports is largely what micro-controllers do, so making this fast is a very good thing. LIT-CSTORE was not in the FMITE but was added to the Stundurd specifically to make functions such as WARNING-ON more efficient --- LIT-CSTORE doesn't access the stack, as SLIT12 followed by CSTORE21 would, which is important if there are some other data already on the stack (there isn't in WARNING-ON but there might be in more complicated functions).

Here is a more general-purpose function used for accessing I/O:
: set-bits  \ port mask --      \ set bits in port according to mask
    over c@  or  swap c! ;

This would compile like this:
s" set-bits" header
    HUFF12
s" set-bits" header21
    OVER22
    CFETCH22
    IOR21
    SWAP12
    CSTORE21
    RETURN

In this case we have two data on the stack. Then we drop down to one datum because IOR21 consumes the mask. Then SWAP12 brings us back up to two data, which is convenient because that is how many CSTORE21 needs. SET-BITS contains six instructions whereas WARNING-ON contains five instructions, so SET-BITS is slightly slower. SET-BITS does a lot of huffing and puffing of data (OVER22, SWAP12 and CSTORE21 all access memory), whereas WARNING-ON didn't do any huffing and puffing. Assuming that memory access is slow, SET-BITS is going to be significantly slower than WARNING-ON although they have almost the same number of instructions.

It is not necessarily true that memory access is particularly slow. An FPGA will have memory internal to the chip, and it should be almost as fast as register access. The MiniForth was built in 1994 on a Lattice isp1048 PLD that did not have internal memory, so my thinking in the design of the Stundurd processor comes from that era. The Stundurd processor can address up to 32KB of RAM and 32KB of non-volatile memory. This seems like quite a lot of memory to have internal to a chip --- it is possible that some versions of the Stundurd will have external memory because doing so allows for a less-expensive FPGA to be used --- the Stundurd is designed to minimize memory access, so it would be a good candidate for an implementation with external memory. In a dual-core system, one core would contain the main program and would have external memory (the full 32KB+32KB) whereas the other core would contain the I/O code and would use internal memory (the common-memory would also be internal) --- this would make sense for an FPGA that has only a few KB of internal memory, as that is all that is needed for I/O.

Just for comparison, here is how SwiftForth v-3.5.7 compiles SET-BITS for the x86:

: set-bits \ port mask --
    over c@  or  swap c! ;  ok
see set-bits
478F0F   4 # EBP SUB                    83ED04
478F12   EBX 0 [EBP] MOV                895D00
478F15   4 [EBP] EAX MOV                8B4504
478F18   EBX EBX XOR                    31DB
478F1A   0 [EAX] BL MOV                 8A18
478F1C   0 [EBP] EBX OR                 0B5D00
478F1F   4 # EBP ADD                    83C504
478F22   0 [EBP] EAX MOV                8B4500
478F25   BL 0 [EAX] MOV                 8818
478F27   4 [EBP] EBX MOV                8B5D04
478F2A   8 # EBP ADD                    83C508
478F2D   RET                            C3 ok

This is VFX v-4.60 for the x86:

see set-bits
SET-BITS
( 0051B790    8B5500 )                MOV       EDX, [EBP]
( 0051B793    0FB612 )                MOVZX     EDX, Byte Ptr 0 [EDX]
( 0051B796    0BDA )                  OR        EBX, EDX
( 0051B798    8B5500 )                MOV       EDX, [EBP]
( 0051B79B    881A )                  MOV       0 [EDX], BL
( 0051B79D    8B5D04 )                MOV       EBX, [EBP+04]
( 0051B7A0    8D6D08 )                LEA       EBP, [EBP+08]
( 0051B7A3    C3 )                    NEXT,
( 14 bytes, 8 instructions )
 ok

The Stundurd processor has 6 instructions for a total of 6 bytes, whereas VFX generates 8 instructions for a total of 14 bytes. Of course, it is not really fair to compare a micro-controller to a desktop-computer, but this is a big difference that seems note-worthy. Micro-controller code can be quite bloated too. The AVR, for example, has 16-bit opcodes working with 8-bit data, so the code is very bloated --- Stundurd code should be both smaller and faster than AVR code, even given the new XMEGA version of the AVR --- Stundurd code should be better than MSP-430 code too, although not so much (to be fair, the AVR is old technology, as it came out only a couple of years after the MiniForth did, whereas the MSP-430 is quite new).


section 9.) premature optimization versus robust design

In Stundurd Forth, TRUE is defined as 1 (rather than -1 as in ANS-Forth). The purpose of this is so the 1 can be used for incrementing a count (our COUNT-FEMALES quotation shown earlier was an example of doing this). Note that NOT only toggles the low bit (the bit being used as a flag), rather than all the bits as in ANS-Forth. The purpose of using -1 for the true-flag (as done in ANS-Forth, Forth-83, etc.) was so the flag could be used as a mask for logical operations --- examples of this use-case are quite rare and typically done better in other ways --- if the use of a flag as a mask is really desired though, then just negate the flag to get the bit mask.

Recently on comp.lang.forth an example of using a flag as a mask was given (modified slightly here to make it ANS-Forth):

: >CHAR  ( [0,15] -- char )
    DUP 9 > 7 AND + [CHAR] 0 + ;

A Forther (Hans Bezemer) complained that this code is bad style, and the Forth-200x committee-member Bernd Payson defended it:
On Sunday, May 24, 2015 at 5:21:05 PM UTC-7, Bernd Paysan wrote:
> Hans Bezemer wrote:
> > ...True, it
> > is a clever piece of programming, but in our opinion it is bad
> > style. Why? Because you are using a flag as a bitmask, which is a
> > completely different datatype. Although there is no such thing as
> > data typing in Forth, this way of programming makes it
> > difficult to understand and maintain a program, which the
> > ANS-Forth standard acknowledges:
>
> Honestly, this is only a problem if you don't know that idiom.  A lot of
> people don't know that you can use masks and logical operations, so they
> will find that operation strange.
> ...
> Therefore, I would reiterate what I told Hugh some times: If you don't know
> something, it's *not* the fault of the person who uses and knows that thing.
> It's entirely your fault, and if you want to be a wise person, you'd rather
> learn it that complain.
>
> IMHO the whole datatype based thinking about cells in Forth is ill-advised.
> First, and foremost, a cell is a bit pattern, and if you add and subtract
> it, it's a mod 2^n ring.  You can use that to some degrees as integer, but
> it's not an integer.  It's a cell.
>
> --
> Bernd Paysan
> "If you want it done right, you have to do it yourself"

Elizabeth Rather responded:
> Thank, you, Bernd, well-said.
>
> Cheers,
> Elizabeth

A little later we had this:
On Tuesday, May 26, 2015 at 11:37:37 AM UTC-7, Elizabeth D. Rather wrote:
> On 5/26/15 8:15 AM, rickman wrote:
> > On 5/26/2015 1:20 PM, WJ wrote:
> >> That code is unreadable and unmaintainable.  It's very hard
> >> to figure out how it accomplishes its task.  I would not
> >> pay a programmer to produce code like that.
> >>
> >> This is somewhat more understandable:
> >>
> >> : >char
> >>    dup 9 > if [char] A 10 - else [char] 0 then
> >>    + ;
> >
> > If you have any reason to look at the definition of >char then I can't
> > see how you would not understand how it works.  Perhaps this would be a
> > better definition...
> >
> > \ Convert n to ASCII char
> > : >CHAR ( n -- char ) DUP 9 > 7 AND + ASCII 0 + ;
> >
> > Lol, saying it is unreadable and unmaintainable is a bit of a stretch. I
> > think that exact code has been read and understood as well as maintained
> > for many years now.  I am pretty sure I have seen something similar to
> > it way back when I was learning assembly language.  I think it took me
> > two minutes to see what it was doing.
>
> Indeed, proper documentation as in rickman's version above is essential
> to readable & maintainable code. Neither of the previous versions is
> acceptable, although I find the shorter code quite clear (and, as
> rickman notes, it's been around for many years). I would have preferred
> [CHAR] instead of ASCII, however, as it's Standard.
>
> Cheers,
> Elizabeth

It is not really that I (Hugh Aguilar, slammed by Bernd Payson for being unwise) don't know how to use a flag as a mask in logic-arithmetic --- it is just that I don't want to --- this is my own code (written in ANS-Forth, and one of the previous versions mentioned above as not being acceptable):

: indexed-char  \ index adr cnt -- char         \ the string will be used as an array of chars
    rover 0< abort" *** INDEXED-CHAR given a negative index ***"
    rover <= abort" *** INDEXED-CHAR given an index too large ***"
    + c@ ;

: hexit>char  \ [0,15] -- char
    s" 0123456789ABCDEF" indexed-char ;

This is an example of how I relate to Forth differently from most ANS-Forth and Forth-200x enthusiasts (I'm one of the few people on the planet who has had a paying job writing Forth code). I consider >CHAR above to be tricky code (the 7 is a "magic number" that is only going to be meaningful to somebody who has memorized the ascii character set) --- these kinds of tricks were done in the 1970s when programmers' primary goal was to save memory. Of course, the Stundurd only has 32KB of RAM, so we are back to saving bytes again. Surprisingly however, >CHAR is not going to save memory on the Stundurd (the string in HEXIT>CHAR is in constant-memory so it doesn't take up any of the valuable 16KB of program-memory or 16KB of RAM). Also surprisingly, >CHAR is not going to save time on the Stundurd (we don't have a CMP instruction, so >CHAR would have to call the > function to compare the number to 9, which would be slow). This is an example of why it is a bad idea for programmers of high-level languages to focus too much on optimization --- code that compiles efficiently on one processor may compile inefficiently on another processor due to differences in the instruction sets --- and the Stundurd is a lot different from mainstream processors, so most of what programmers "know" about optimization, will not be true on the Stundurd.

All in all, I hope that Stundurd programmers strive first to write readable code, and only go back later to rewrite it to be more compact if absolutely necessary. Employers don't pay programmers to write clever but unreadable code --- they mostly just want to get a working product shipped so the customer(s) will give them money --- if programmers enjoy solving puzzles, there are many fun puzzles to play with (for example, some old guys spend their free time writing 6502 assembly-language programs for retro computers such as ye olde Commodore-64), but playing with puzzles should not be done in the workplace if employees want to stay employed. Stundurd is all about practicality! ANS-Forth and Forth-200x are puzzling and impractical. Another good point here is that if a function is general-purpose, then it can be reused several times, and this reuse may end up saving more memory than would be saved by writing clever code several times each slightly different. In my code, INDEXED-CHAR is general-purpose; it can be used for any character translation problem (the 8086 designers considered character translation to be so common that they provided the XLATB instruction for this purpose).


section 10.) iteration with BEGIN WHILE REPEAT

It is sometimes necessary to find the tail node of a list. We will assume here that the first field in the struct is .FORE that is the pointer to the next node. Here is a simplistic version of the TAIL ( head -- node ) function:

: tail  \ head -- node
    dup 0= if  exit then
    begin  dup .fore @  dup while               \ -- node next
        nip  repeat drop ;

A non-optimizing compilation would be this:
s" tail" header21
    puff12
s" tail" header
    DUP-ZERO?  RETURN  NOP  ??                  \ this is the IF ... THEN
1 label                                         \ this is the BEGIN
    DUP
    FETCH
    DUP-ZERO?  label:2 BRANCH  ??               \ this is the WHILE     \ effectively the same as 0BRANCH in classic Forths
    NIP
    label:1 BRANCH                              \ this is the REPEAT
2 label
    DROP
    RETURN

Sometimes it is necessary for WHILE to compile as a conditional branch because the code after the REPEAT is lengthy. In this case however, the code after the REPEAT is short enough that the optimizer can put it in the skip-area like this:
s" tail" header21
    puff12
s" tail" header
    DUP-ZERO?  RETURN  NOP  ??
1 label
    DUP
    FETCH
    DUP-ZERO?  DROP  RETURN  ??
    NIP
    label:1 BRANCH

Our Stundurd code was just written badly though. We can rewrite it to be more efficient:

: tail  \ head -- node
    0 swap  begin                               \ -- last-node current-node
        dup while  nip  dup .fore @  repeat drop ;

This compiles as:
s" tail" header21
    puff12
s" tail" header
    0 LIT12
    SWAP22                                      \ last-node current-node
    DUP-ZERO?  DROP21  RETURN  ??               \ drop the current-node (it is NIL at this time) and return the last-node
1 label
    NIP21                                       \ nip the last-node (this expands to nothing)
    DUP12
    FETCH22                                     \ this is the new current-node
    NONZERO?  label:1 BRANCH  ??
    DROP21
    RETURN

The reason why the second version was more efficient than the first version is that the second version put all the code between the WHILE and the REPEAT so it could get optimized (the NIP compiles into nothing). By comparison, the first version had some code in front of the WHILE and some code after the WHILE, so the optimizer couldn't work on it as a single block of code. This trick, of not splitting code blocks, should work on all optimizing Forth compilers (VFX, for example).

The above compilation of TAIL was done to enhance speed. A compilation done to enhance compactness would look like this:
s" tail" header21
    puff12
s" tail" header
    0 LIT12
    SWAP22                                      \ last-node current-node
1 label
    DUP-ZERO?  DROP21  RETURN  ??               \ drop the current-node (it is NIL at this time) and return the last-node
    NIP21                                       \ nip the last-node (this expands to nothing)
    DUP12
    FETCH22                                     \ this is the new current-node
    label:1 BRANCH

It is idiomatic in Scheme (but not in Stundurd Forth) for programmers to use self-recursion for iteration. It is somewhat of a mystery as to why the Schemers do this. The most likely explanation is that early compilers didn't do any optimization, and so the Schemers would hand-write their code using this awkward construct to get improved performance, but then they considered it to be idiomatic and continued doing it even after optimizing compilers were introduced. The Common-Lisp crowd seems to have gotten over doing that though. It not idiomatic in Stundurd Forth, but it is not a great sin either, so if recalcitrant Scheme programmers want to continue doing this in Stundurd that is okay --- here is TAIL using the self-recursion method:

: <tail>  \ last-node current-node -- tail-node
    dup 0= if  drop  exit then                  \ -- last-node
    nip  dup .fore @                            \ -- current-node next-node
    recurse ;

: tail  \ head -- node
    0 swap  <tail> ;

<TAIL> compiles like this:
s" <tail>" header
    HUFF12
s" <tail>" header21
    DUP-ZERO?  DROP21  RETURN  ??
    NIP21
    DUP12
    FETCH22
    ' <TAIL> BRANCH

TAIL compiles like this:
s" tail" header21
    PUFF21
s" tail" header
    0 LIT12
    SWAP22
    ' <TAIL> BRANCH

It is typical when using self-recursion for iteration, to have a low-level function that does the work and a high-level function that sets up the data-stack for the low-level function. The naming convention in Stundurd (Forth too) is to give the functions the same name, except with pointy brackets around the low-level function's name. In the above example, <TAIL> was the low-level function and TAIL was the high-level function. Note that making the low-level function a quotation (recommended by Bernd Payson for Forth-200x code) doesn't work because RECURSE doesn't work in quotations:

: tail  \ head -- node
    0 swap
    {
    dup 0= if  drop  exit then                  \ -- last-node
    nip  dup .fore @                            \ -- current-node next-node
    recurse
    }
    execute ;

Aside from not working in Stundurd Forth, this is extremely ugly code such as the Forth-200x followers are fond of writing. In Stundurd Forth it is idiomatic to have only one-line quotations. It is best not to have big clunkers like this. Also, the programmer should never EXECUTE a quotation from within the parent function as done above --- there is no circumstance in which you would ever want to do that.

Here is the WMOVE ( source-adr destination-adr cnt -- ) function:
s" wmove" header
    HUFF12
s" wmove" header21
    -ROT22
    >GP21
    DUP-ZERO?  DROP  RETURN  ??
    1 LSHR                                      \ CNT was for bytes, is now for cells (the block size has to be a multiple of two)
1 label
    WMOVE-GP
    DUP-NONZERO?  label:1 BRANCH  ??
    DROP
    RETURN

WMOVE is pretty important, so it can be unwound as much as desired:
s" wmove" header
    HUFF12
s" wmove" header21
    -ROT22
    >GP21
    DUP-ZERO?  DROP  RETURN  ??
    1 LSHR                                      \ CNT was for bytes, is now for cells (the block size has to be a multiple of two)
1 label
    WMOVE-GP
    DUP-NONZERO?  WMOVE-GP  NOP  ??
    DUP-NONZERO?  WMOVE-GP  NOP  ??
    DUP-NONZERO?  WMOVE-GP  NOP  ??
    DUP-NONZERO?  WMOVE-GP  NOP  ??
    DUP-NONZERO?  WMOVE-GP  NOP  ??
    DUP-NONZERO?  WMOVE-GP  NOP  ??
    DUP-NONZERO?  WMOVE-GP  NOP  ??
    DUP-NONZERO?  label:1 BRANCH  ??
2 label
    DROP
    RETURN

The NOP may not be significantly faster than the BRANCH though. Here is a bulkier but faster version:
s" wmove" header
    HUFF12
s" wmove" header21
    -ROT22
    >GP21
    DUP-ZERO?  DROP  RETURN  ??
    1 LSHR                                      \ CNT was for bytes, is now for cells (the block size has to be a multiple of two)
1 label
    WMOVE-GP
    DUP-ZERO?  DROP  RETURN  ??
    WMOVE-GP
    DUP-ZERO?  DROP  RETURN  ??
    WMOVE-GP
    DUP-ZERO?  DROP  RETURN  ??
    WMOVE-GP
    DUP-ZERO?  DROP  RETURN  ??
    WMOVE-GP
    DUP-ZERO?  DROP  RETURN  ??
    WMOVE-GP
    DUP-ZERO?  DROP  RETURN  ??
    WMOVE-GP
    DUP-ZERO?  DROP  RETURN  ??
    WMOVE-GP
    DUP-NONZERO?  label:1 BRANCH  ??
    RETURN

The EXCHANGE ( adrA adrB cnt ) is similar to WMOVE except that we use WEXCH-GP rather than WMOVE-GP. The WEXCH-GP instruction can also be used for the OBTAIN( sem-adr -- ) function that is used to obtain control of a semaphore:

s" obtain" header21
    PUFF21
s" obtain" header
    LINK
    TRUE
    INIT-LOCAL                  \ #1 local is our flag (set to TRUE)
    1 LIT12
    LOCAL
    DINIT-LOCAL21               \ #2 local has sem-adr in low-word and our flag's adr in high-word
1 label
    2 LOCAL>GP                  \ GPL = sem-adr, GPH = true-adr
    0 LIT                       \ SOS = undefined, TOS = 0
    WEXCH22                     \ SOS = what was in SEM-ADR
    DROP21
    ZERO?  UNLINK  NOP  ??      \ we read that the semaphore was FALSE so nobody had possession of it, and we set the semaphore to TRUE so we have possession now
    TRUE LIT
    1 LIT12
    LOCAL22
    STORE21                     \ our flag got set to FALSE, so set it to TRUE again
    label:1 BRANCH

?DUP is deprecated. It tends to reduce readability and it is inefficient. For the most part, programmers are encouraged to use this idiom:
    BEGIN  DUP WHILE ... REPEAT DROP
This compiles as:
1 label
    DUP-ZERO?  label:2 BRANCH  ??
    ...
    label:1 BRANCH
2 label
    DROP                                \ this might be DROP21 if the loop had SOS and TOS valid throughout

This is the classical Forth idiom:
    BEGIN  ?DUP WHILE ... REPEAT
This compiles as:
1 label
    DUP-ZERO?  DUP12 PUFF21  ??         \ this is compiled by the ?DUP macro
    ZERO?  label:2 BRANCH  ??           \ this is like the classical 0BRANCH
    ...
    label:1 BRANCH
2 label

This is inefficient because we have more code being executed inside of the loop. Also, it is less readable because the test for zero is being done twice on the same datum, which is awfully confusing (the designer of Stundurd Forth thought that ?DUP was confusing way back in 1984 when he was 18-years-old and learning Forth, and continues to think so today).

We had hardware support for WMOVE (the WMOVE-GP primitive) shown above, so it was pretty efficient. By comparison, WMOVE> has to be written in Forth, so it is going to be much slower. WMOVE should be used routinely. WMOVE> should only be used in the rare case that the blocks of memory overlap, and the destination is above the source (that is what the > signifies). The only known use-case for WMOVE> is expanding an array to allow a new element to be inserted into the middle --- this is pretty rare, as a linked-list is a better choice if insertions are needed.

: wmove>  \ src-adr dst-adr cnt --      \ WMOVE> goes from upper addresses to lower addresses (WMOVE goes from lower to upper)  \ CNT must be a multiple of 2
    >r
    swap r@ +  swap r@ +                \ -- src-lim dst-lim
    r> begin  dup while  >r
        swap 2-  swap 2-
        over @  over !
        r> 2-  repeat 3drop ;

In Stundurd, any positive literal with a minus-sign suffix will compile as that number followed by MINUS. The 1- compiles the same as 1 - compiles. Similarly, 1+ compiles the same as 1 + compiles. This works for any positive literal (not just 1 as in ANS-Forth).

Here is how WMOVE> gets compiled:
s" wmove>" header
    HUFF12
s" wmove>" header21
    TOR21
    SWAP12
    PUFF21
    RFETCH12
    PLUS21
    SWAP12
    PUFF21
    RFETCH12
    PLUS21
    RFROM12
    DUP-ZERO?  label:2 BRANCH  ??
1 label
    TOR21
    SWAP12
    -2 LIT-PLUS
    SWAP22
    -2 LIT-PLUS
    OVER22
    CFETCH22
    OVER22
    CSTORE21
    RFROM12
    -2 LIT-PLUS
    DUP-NONZERO?  label:1 BRANCH  ??
2 label
    3DROP21
    RETURN


section 11.) some common Stundurd Forth words (and a discussion of Stundurd style)

This section provides some common Stundurd words. We only had 64 primitives, so some words that would be primitives in a classical Forth system, have to be implemented as colon words in Stundurd.

Here is the S>D ( s -- d ) function:
s" s>d" header21
    PUFF21
s" s>d" header
    DUP
    NONNEG?  0 LIT  RETURN  ??
    -1 LIT
    RETURN

This doesn't work:
s" s>d" header21
    PUFF21
s" s>d" header
    DUP
    NEG?  -1 LIT  RETURN  ??    \ -1 LIT compiles as  1 SLIT  NEG  which is 2 bytes, then the RETURN is a 3rd byte, so ?? aborts
    0 LIT
    RETURN

Here is the > ( a b -- a>b? ) function:
s" >" header
    HUFF12
s" >" header21
    MINUS21
    POS?  TRUE  RETURN  ??      \ A-B was positive, so A>B, so return TRUE
    FALSE                       \ A-B was non-positive, so A<=B, so return FALSE
    RETURN

Here is the < ( a b -- a<b? ) function:
s" <" header
    HUFF12
s" <" header21
    MINUS21
    NEG?  TRUE  RETURN  ??      \ A-B was negative, so A<B, so return TRUE
    FALSE                       \ A-B was non-negative, so A>=B, so return FALSE
    RETURN

U< is mostly used in classical Forth for comparing addresses, but all data addresses on the Stundurd are in the upper 32K, so U< is not really needed. U< is quite inefficient compared to the < function because the Stundurd doesn't have an overflow-flag and hence we need to do the calculation in double-precision. If the user really wants U< ( ua ub -- ua<ub? ) though, then here is the function:
s" u<" header21
    PUFF21
s" u<" header
    0 SLIT12                    \ SOS:TOS is UB as a double
    DNEG22
    >GP21                       \ GPL:GPH are now UB as a double and negated
    0 SLIT12                    \ SOS:TOS are now UA as a double
    DPLUS22
    NIP21                       \ we only need the high cell to test for negative
    NEG?  TRUE  RETURN  ??      \ UA-UB was negative, so UA<UB, so return TRUE
    FALSE                       \ UA-UB was non-negative, so UA>=UB, so return FALSE
    RETURN

Here is the famous */ ( a b c -- a*b/c ) function:
s" */" header
    HUFF12
s" */" header21
    TOR21                       \ hold C on return-stack while we do the multiplication
    HUFF12
    SIGN22
    UMULT22
    DDROP21                     \ SOS:TOS were not needed (the product is also in GPL:GPH)
    RFROM
    UDIV12                      \ SOS is the remainder and TOS is the quotient
    NIP21                       \ we only need the quotient
    SWAP                        \ this is the sign
    NEG?  NEG  RETURN  ??
    RETURN

Here is the MIN ( a b -- min ) function:
s" min" header
    HUFF12
s" min" header21
    DDUP22
    MINUS21
    POS?  NIP  RETURN  ??       \ A-B was positive, so A>B, so return B
    DROP                        \ A-B was non-positive, so A<=B, so return A
    RETURN

Here is the MINMAX ( a b -- min max ) function:
s" minmax" header
    HUFF12
s" minmax" header21
    DDUP22
    MINUS21
    POS?  SWAP12  PUFF21  ??    \ A-B was positive, so A>B, so return B A
    RETURN                      \ A-B was non-positive, so A<=B, so return A B

Here is the RSHIFT ( a b -- a*(2^-b) ) function (unsigned):
s" rshift" header21
    PUFF21
s" rshift" header
    15 LIT-AND
    ASHL                        \ multiply by 2 because each element in the jump-table is 2 bytes
    label:1 LIT12
    PLUS21
    GOTO
1 label                         \ -- A
     NOP     RETURN
     1 LSHR  RETURN
     2 LSHR  RETURN
     3 LSHR  RETURN
     4 LSHR  RETURN
     5 LSHR  RETURN
     6 LSHR  RETURN
     7 LSHR  RETURN
     8 LSHR  RETURN
     9 LSHR  RETURN
    10 LSHR  RETURN
    11 LSHR  RETURN
    12 LSHR  RETURN
    13 LSHR  RETURN
    14 LSHR  RETURN
    15 LSHR  RETURN

We also have LSHIFT that is like RSHIFT except with LSHL rather than LSHR. RSHIFT and LSHIFT assume that the B value is unknown at compile-time, but there is no use-case for this that the author is aware of. Normally the B value is known at compile-time and so LSHR or LSHL can be compiled. This is useful in micro-controllers that have a lot of flags and very little memory, because it allows 16 flags to be packed into a single cell; this is common in a PLC (programmable-logic-controller). Also, in a micro-controller, it is quite common for the programmer to access a small block of bits in the middle of an I/O port.

LSHR and LSHL are only for 16-bit data; we also have DLSHR and DLSHL for 32-bit data in SOS:TOS. We don't have any way to shift big integers of 64-bit or 128-bit, so the Stundurd won't be able to support encryption algorithms involving LFSRs (linear-feedback-shift-registers). The best bet for encryption on the Stundurd would be the Spritz algorithm (an upgraded version of the famous RC4) --- RAM is less expensive nowadays than it used to be, so the 256-byte array is becoming realistic for micro-controllers (AES is designed to work on smart-cards).

Here is the HALVES ( a b -- a*(2^-b) ) function (signed):
s" halves" header21
    PUFF21
s" halves" header
    15 LIT-AND
    NEG
    15 LIT-PLUS                 \ -- 15-B
    label:1 LIT12
    PLUS21
    GOTO
1 label
    ASHR
    ASHR
    ASHR
    ASHR
    ASHR
    ASHR
    ASHR
    ASHR
    ASHR
    ASHR
    ASHR
    ASHR
    ASHR
    ASHR
    ASHR
    RETURN

Here is the DDUP ( a b -- a b a b ) function:
s" ddup" header
    HUFF12
s" ddup" header21
    >GP21
    GP12
    PUFF21
    GP12
    PUFF21
    RETURN

Here is the DOVER ( a b c d -- a b c d a b ) function:
s" dover" header
    HUFF12
s" dover" header21
    TOR21
    TOR
    HUFF12
    >GP21
    GP12
    PUFF21
    RFROM
    RFROM
    GP12
    PUFF21
    RETURN

Here is the DSWAP ( a b c d -- c d a b ) function:
s" dswap" header
    HUFF12
s" dswap" header21
    >GP21
    TOR
    TOR
    GP12
    PUFF21
    RFROM
    RFROM
    RETURN

Here is the DROT ( a b c d e f -- c d e f a b ) function:
s" drot" header
    HUFF12
s" drot" header21
    TOR21
    TOR
    TOR
    TOR
    HUFF12
    >GP21
    RFROM
    RFROM
    RFROM
    RFROM
    GP12
    PUFF21
    RETURN

All of the words in Standard Forth that work with double-cell values (2OVER 2SWAP 2ROT etc.) have a 'D' prefix in Stundurd Forth: DOVER DSWAP DROT etc. (also, DR@ works differently from 2R@ as described already in section-5).

A major cause of unreadability in Forth programs is mixing single-cell and double-cell data on the stack, and then using a lot of stack-juggling to access the data. Stundurd Forth has local variables that are capable of storing either single-cell or double-cell values. The best way to work with double-cell data is to define some locals and hold the doubles in them. Use D@ and D! to access them. The source-code will be a lot more readable, and may be more efficient as well (functions like DROT above are pretty time-consuming). At one time in the design, DFETCH12 was a primitive, but this got demoted to being a macro --- it is expected that double-precision arithmetic will not be used much on the Stundurd --- double-cell values will more likely be strings or xt values, rather than integers.

Even if you are just working with single-cell data, if you have a lot of stack-juggling then the use of locals will likely result in more readable source-code (likely faster machine-code too, if you have more than three data in use). The Stundurd is one of the few Forth micro-controllers that supports locals in the instruction set (we can be pretty sure that Charles Moore's processors won't support locals in this universe's lifetime) --- so use locals on the Stundurd to write readable and efficient Stundurd programs (Stundurd source-code is not supposed to be a puzzle that has to be solved like Sudoku). On the other hand, the hallmark of recalcitrant C programmers is the over-use locals --- this will result in ugly source-code (especially if the locals have meaningless names) and inefficient machine-code (especially if a local is used only once or twice in a function) --- then they complain bitterly that Forth is ugly and inefficient, and say that they are in a hurry to get back to writing C code for mainstream processors (my response is: "Don't let the door hit you in the ass on the way out!")

The manual for ISYS Forth (for the Apple-IIc) gave us this example of good Forth style:

: par  \ r1 r2 -- r                                 \ calculate parallel resistance of two resistors
    ddup +  */ ;

: par3  \ r1 r2 r3 -- r                             \ calculate parallel resistance of three resistors
    par par ;

The high-functioning C'diot may avoid stack-juggling (the DDUP in PAR above) like this:

: par  local{ r1 r2 -- r }                          \ calculate parallel resistance of two resistors
    r1 @  r2 @
    r1 @  r2 @  +  */ ;

: par3  local{ r1 r2 r3 -- r }                      \ calculate parallel resistance of three resistors
    r1 @  r2 @  par
    r3 @  par ;

The low-functioning C'diot will do even worse. For one thing, he may fail to understand */ because he can't translate it into C code --- so he will use * and / instead, resulting in an overflow bug. Or, he may fail to understand */ but will understand that overflow is an issue --- so he will use D* and D/ instead, resulting in abysmally slow code. Also, he may fail to understand that one of the purposes of factoring is so that sub-functions can be reused (PAR was reused in PAR3) because factoring is not considered to be a virtue in the C world. A collision of not understanding */ and not understanding reusability, would result in this:

: par  local{ r1 r2 r3 -- r }                       \ calculate parallel resistance of two resistors (WARNING: overflow is possible!)
    r1 @  r2 @  *
    r1 @  r2 @  +  / ;

: par3  local{ r1 r2 r3 | t1 -- r }                 \ calculate parallel resistance of three resistors (WARNING: overflow is possible!)
    r1 @  r2 @  *
    r1 @  r2 @  +  /  t1 !
    t1 @  r3 @  *
    t1 @  r3 @  +  / ;

The Stundurd code above appears to have been written in C first, and then translated line-by-line into Stundurd; it is pretty much just an rpn-version of C. It is typical for C'diots to have a function such as PAR3 that obviously contains cut-and-paste code from another function (the PAR function just above it). It is also typical for C'diots to comment their bugs (as done above, with the comments warning that overflow is possible). Of course, the true C'diot would put a comment on every line in a vain effort at improving readability --- and then criticize the good-style version of PAR and PAR3 for not being adequately commented!

A good way to avoid stack-juggling is to use structs, and only have the pointers to the structs on the data-stack. Our LINE.LENGTH function shown earlier was an example of this. Stundurd provides a heap (that is something else we can expect that Charles Moore won't provide ever), so the heap should be used. Whenever several data are used together and are only meaningful in relation to each other (like the X and Y coordinates of a point), then these data should be packed together into a struct and the struct held in the heap, and only the pointer to the struct passed around on the stack. This greatly reduces the amount of data on the stack, which increases both readability and efficiency.

For the most part, stack juggling should be avoided. We do have ROVER RIP and RUCK that are some new stack-juggling words that can be be used when necessary. The 'R' in their names indicate that they work with the third element of the stack, similar to how ROT works with the third element.

Here is the ROVER ( a b c -- a b c a ) function (it is like OVER except for the 3rd element rather than the 2nd):
s" rover" header
    HUFF12
s" rover" header21
    ROVER22             \ this is a primitive
    PUFF21
    RETURN

Here is the RIP ( a b c -- b c ) function (it is like NIP except for the 3rd element rather than the 2nd):
s" rip" header
    HUFF12
s" rip" header21
    RIP22               \ this is a macro that expands as:  >GP21 DROP GP12
    PUFF21
    RETURN

Here is the RUCK ( a b c -- c a b c ) function (it is like TUCK except that the datum goes under the 3rd element rather than the 2nd):
s" ruck" header
    HUFF12
s" ruck" header21
    RUCK22              \ this is a macro that expands as:  -ROT22 ROVER22
    RETURN


section 12.) iteration with lambda functions (this section introduces a new concept for most Forthers)

Earlier we discussed linked lists (in our COUNT-FEMALES example). This is the struct definition for list:

0
    w field .fore
constant list

Any struct that uses LIST as its parent data-type (as EMPLOYEE did) will have the .FORE field in front of its own fields, and |EACH will work on it; this is inheritance. We used |EACH ( head xt -- ) for traversing a linked-list. This is a higher-order function; lists are the primary data-structure used in Stundurd, so |EACH is pretty fundamental to the language.

Here is a first-attempt at the code:

: |each  local{ head :xt -- }
    head @
    begin  dup while  dup @ >r  :xt d@ execute  r> repeat drop ;

This is inefficient because the HEAD local variable gets created, then the value is put back on the stack and the HEAD local is never used again. Here is a more efficient version in which the head value is just left on the stack and only :XT gets made into a local variable:

: |each  \ head --
    local{ :xt -- }
    begin  dup while  dup @ >r  :xt d@ execute  r> repeat drop ;

Here is how |EACH compiles:

s" |each" header
    HUFF12
s" |each" header21
    LINK
    DINIT-LOCAL
    DUP-ZERO?  label:2 BRANCH  ??
1 label                         \ -- current-node
    DUP12
    FETCH22
    TOR21
    1 LOCAL>GP
    EXECUTE-GP
    RFROM
    DUP-NON-ZERO?  label:1 BRANCH  ??
2 label
    DROP
    UNLINK

The next node pointer is fetched from the .FORE field of the current node and this is pushed to the return-stack. If we had pushed a copy of the current node to the return-stack, and then tried to fetch the next node pointer after pulling it back from the return stack, we might fail. It is legal for the quotation to destroy the node that it is given. The node is presumably in the heap, so the quotation may deallocate it, in which case it is not guaranteed to retain its contents. Also, the quotation may move the node to a different list, in which case it will get a new .FORE value. The way |EACH is written above, the quotation can do pretty much anything with the node that it is given (including inserting it into another list). It is not allowed to mess with other nodes however.

We use |EACH as the name of our higher-order function. The | prefix indicates that the quotation will have access to the parent function's data-stack items. This is accomplished in |EACH above by holding the internal data (the next-node pointer) on the return-stack while executing the quotation. This gets the internal data out of the way so that when the quotation executes there is nothing on the data-stack on top of the parent function's own data.

We don't have DO loops in Stundurd. Instead we have |ITERATE ( how-many :xt -- ) that is a higher-order function:

: |iterate  \ how-many --
    local{ :xt -- }
    begin  dup while                \ -- how-many
        >r
        :xt d@ execute
        r> 1- repeat drop ;

s" |iterate" header
    HUFF12
s" |iterate" header21
    LINK
    DINIT-LOCAL
    DUP-ZERO?  DROP  UNLINK  ??
1 label
    TOR
    1 LOCAL>GP
    EXECUTE-GP
    RFROM-LOOP?  label:1 BRANCH  ??
    DROP
    UNLINK

Stundurd doesn't have the DO loop. A DO loop such as provided in ANS-Forth is difficult to implement on the Stundurd because the Stundurd doesn't have an overflow flag like most mainstream processors. The purpose of ANS-Forth's tricky implementation of DO involving the overflow-flag is to allow DO loops to work with unsigned addresses that cross the halfway threshold (high bit set), and to also work with signed integers that cross the zero threshold. As clever as all of this is, it is not necessary on the Stundurd because our addresses are all in the upper 32KB anyway.

If a person really really wants this cruft, then DO I J LOOP and +LOOP can be written in Stundurd with some meta-compiling (although they will only be for signed values due to the overflow-flag issue, and working around this problem will make it yet more inefficient). All in all, DO loops are a bad idea and the designer of Stundurd won't implement them --- it is not that I can't --- I just don't want to.

|ITERATE is the idiomatic way to do iteration in Stundurd Forth. For example, in ANS-Forth we might have this for printing a string:

: type  \ adr cnt --                            \ the CNT is unsigned
    over + swap ?do  I c@ emit  loop ;

In Stundurd, this would be:

: type  \ adr:cnt --                            \ the CNT is unsigned       \ the colon in ADR:CNT indicates that ADR and CNT are related
    { dup c@ emit  1+ }  |iterate drop ;

This would compile as:
s" type" header
    HUFF12
s" type" header21
    aaa LIT             \ aaa is the cfa of our quotation
    QXT12
    ' |ITERATE CALL21
    DROP
    RETURN

The quotation compiles as:
    DUP
    CFETCH
    ' EMIT CALL
    INC
    RETURN

Quotations nominally need QLINK at the beginning and QUNLINK at the end. This is actually only necessary if the quotation accesses local variables in the parent function. Our quotation above didn't access locals, so QLINK and QUNLINK could be dispensed with. It is okay to put QLINK and QUNLINK in the code when they aren't needed though --- the following code for our quotation would have also worked (somewhat inefficiently though):
    QLINK
    DUP
    CFETCH
    ' EMIT CALL
    INC
    QUNLINK

Here is an ANS-Forth function for printing numbers upwards:

: up.  \ limit base --                          \ assumes LIMIT is above BASE
    ?do  I .  loop ;

In Stundurd Forth, use this:

: up.  \ limit base --                          \ assumes LIMIT is above BASE
    tuck -  { dup .  1+ }  |iterate drop ;

Here is an ANS-Forth function that is like UP. but goes downwards (using ?DO with a negative step is very non-intuitive):

: down.  \ limit base --                        \ assumes LIMIT is below BASE
    swap 1+  swap ?do  I .  -1 +loop ;

In Stundurd Forth, DOWN. would be similar to UP. except that our count is negated and our increment is negative (hopefully this will seem intuitive to the reader):

: down.  \ limit base --                        \ assumes LIMIT is below BASE
    tuck - negate  { dup .  1- }  |iterate drop ;

We could have a function THROUGH. ( limit base -- ) that goes either up or down:

: design  \ val -- |val| sign                   \ converts VAL into an absolute value, and provides SIGN as either -1 or 1 representing sign of original VAL
    dup 0< if  negate  -1  exit then
    1 ;

: through.  \ limit base --                     \ if LIMIT is above BASE iterate up, otherwise iterate down
    tuck -                                      \ -- base count             \ COUNT may be negative
    design -rot                                 \ -- step base count        \ COUNT is positive, STEP is sign of original COUNT
    { dup .  over + }  |iterate 2drop ;

The reader may be wondering what happens if LIMIT equals BASE (causing VAL to be zero). It may seem that DESIGN should return zero when VAL is zero, rather than one. This isn't necessary. |ITERATE and ITERATE are similar to ?DO in ANS-Forth in that they exit prior to its loop if LIMIT equals BASE, so the step value (provided by DESIGN) for use in the quotation is never used because the quotation is never executed. |EACH and |ITERATE both exit prior to the loop they are given a zero (a null pointer for |EACH or a zero count for |ITERATE), and they never execute the quotation in this case.

The advantage of the Stundurd idiom is that all of the complicated iteration code gets hidden away inside of the higher-order function. The application programmer doesn't have to deal with this stuff, which is a good thing because iteration is a common source of bugs. The application programmer's job is much easier if he just has to write the quotation and give it to a higher-order function. Another advantage is that the application program is more compact. Higher-order functions such as |EACH or |ITERATE may get used dozens of times in an application program. If every loop were written explicitely with BEGIN WHILE REPEAT, this would result in quite bloated code. If every loop is written with a quotation and a call to a higher-order function, this results in pretty compact code. The Stundurd only has 32KB of program-memory, so the instruction set is designed to make it easy to write compact code.


section 13.) early exits from higher-order functions (if you didn't understand the last section, you won't understand this section either)

For the most part, higher-order functions replace ?DO in ANS-Forth. One good feature that ?DO and DO have is an early exit with LEAVE --- |ITERATE and |EACH don't allow this.

It is easy to upgrade |ITERATE to allow for an early out. We have the |UNTIL ( how-many xt -- completed ) function:

: |until  \ how-many --
    local{ :xt -- completed }
    dup                                             \ -- original current
    begin  dup while
        >r
        :xt d@ execute if  r> -  exit then          \ return a count of how many iterations were executed successfully
        r> 1- repeat
    drop ;

s" |until" header
    HUFF12
s" |until" header21
    LINK
    DINIT-LOCAL
    DUP
    DUP-ZERO?  label:2 BRANCH  ??
1 label
    TOR
    1 LOCAL>GP
    GP-EXECUTE
    NON-ZERO?  label:3 BRANCH  ??
    RFROM-LOOP?  label:1 BRANCH  ??
2 label
    DROP
    UNLINK
3 label
    RFROM12
    MINUS21
    UNLINK

Now the quotation is required to return a flag indicating if this is the last iteration or not. Our higher-order function |UNTIL tests the flag and branches out of the loop if it is set. |UNTIL returns a count of how many iterations were completed successfully (it doesn't count the iteration that did the early-out, if there was an early-out). To do this, it has to save on the return-stack the initial HOW-MANY value. At the end, it subtracts the last HOW-MANY value from the initial HOW-MANY value to calculate the index (0 for the first iteration, or HOW-MANY for the last iteration).

Explicit iteration is done with BEGIN WHILE REPEAT --- there is no UNTIL or AGAIN as in ANS-Forth --- so our use of the word UNTIL above doesn't conflict.

ANS-Forth has LEAVE for branching out of a ?DO or DO loop, and a comparable feature is easy to implement in Stundurd Forth (our |UNTIL above was just |ITERATE with a branch out of the middle of the loop). ANS-Forth also has UNLOOP followed by EXIT for exiting a function in the middle of a ?DO or DO loop. This feature is not possible to implement in Stundurd. The reason is that we have no guarantee that the higher-order function is called directly by the parent function (although this is usually the case). The parent function may call some sub-function, passing the xt as a parameter, and that function may then call the higher-order function (ITERATE or EACH or whatever); there may actually be a chain of functions between the parent function and the higher-order function. So, the higher-order function can't know what return-addresses are on the return-stack, and hence can't undo the call chain. This is also the reason why it is necessary allow the quotation to access the parent function's local variables. The bar-feature higher-order functions hold their internal data on the return-stack while calling the quotation, so the parent function's data-stack is accessible. We have functions such as UP. DOWN. and THROUGH. that use quotations that access this data. This only works if the higher-order function is called directly by the parent function. If the parent function passes the xt of the quotation to a sub-function, and it calls the higher-order function giving it the xt, that sub-function may have its own internal data on the data-stack getting in the way. If the programmer wants to pass a quotation around (actually the xt of the quotation) and have that quotation communicate with it, without any restrictions, then he should use local variables because these are always accessible from anywhere. Also, if he has several data that need to be accessed, he should use local variables to avoid stack-juggling and improve readability.


section 14.) early exits on list-oriented higher-order functions (like the previous section on early exits, but more difficult)

As another example of an early out, we may want to search a list for a node that matches a pattern, and then return that node. |EACH could be used, but it would search the entire list every time. For efficiency, we only want to search the list up to the point where the node is found (also, so we get the first match if more than one node matches).

For an early-out, we need the |FIND-NODE ( head :xt -- node|false ) function:

: |find-node  \ head --
    local{ :xt -- }
    begin  dup while  dup @     \ -- current-node next-node
        >r  dup >r
        :xt d@ execute  if  rdrop  r>  exit then                \ return the current-node
        r> rdrop                \ -- next-node
        repeat ;                                                \ return the NIL as a FALSE flag

s" |find-node" header
    HUFF12
s" |find-node" header21
    LINK
    DINIT-LOCAL
    DUP-ZERO?  label:2 BRANCH  ??
1 label
    TOR
    DUP12
    TOR21
    1 LOCAL>GP
    EXECUTE-GP
    NON-ZERO?  label:3 BRANCH  ??
    RFROM
    RDROP
    DUP-NONZERO?  label:1 BRANCH  ??
2 label
    UNLINK
3 label
    RDROP
    RFROM
    UNLINK

But, what if we want to remove our found node from the list? This is a singly-linked list, so to remove a node from the list we need the prior node.

The |FIND-PRIOR ( head :xt -- -1|node|false ) function could be written like this:

: |find-prior  \ head --
    local{ :xt -- }
    -1  begin  over while                           \ -- current-node prior-node                \ the -1 means there is no prior-node
        >r  dup @ >r  dup >r                        \ -- current-node                           \r: -- prior-node next-node current-node
        :xt d@ execute if  rdrop rdrop  r>  exit then                                           \ return the prior-node if we have a match
        r> r> swap  rdrop                           \ -- next-node current-node
        repeat drop ;                                                                           \ return the current-node (NIL) as a FALSE flag

This results in inefficient code however, because the Stundurd processor doesn't have a OVER-NONNEG? primitive. Also, we have only the top two stack items in registers (rather than the top three) so OVER requires memory-access whereas SWAP is done entirely in registers. So, the Forth code is more efficient like this:

: |find-prior  \ head --
    local{ :xt -- }
    -1 swap  begin  dup while                       \ -- prior-node current-node                \ the -1 means there is no prior-node
        swap >r  dup @ >r  dup >r                   \ -- current-node                           \r: -- prior-node next-node current-node
        :xt d@ execute if  rdrop rdrop  r>  exit then                                           \ return the prior-node if we have a match
        r> r>  rdrop                                \ -- current-node next-node
        repeat drop ;                                                                           \ return the current-node (NIL) as a FALSE flag

This compiles as:

s" |find-prior" header
    HUFF12
s" |find-prior" header21
    LINK
    DINIT-LOCAL
    -1 LIT12
    SWAP22
    DUP-ZERO?  label:2 BRANCH  ??
1 label                                             \ expects both SOS and TOS valid
    SWAP22
    TOR21
    DUP12
    FETCH22
    TOR21
    DUP12
    TOR21
    1 LOCAL>GP
    EXECUTE-GP
    NON-ZERO?  label:3 BRANCH  ??
    RFROM
    RFROM12
    RDROP
    DUP-NONZERO?  label:1 BRANCH  ??
2 label                                             \ expects both SOS and TOS valid
    DROP21
    UNLINK
3 label                                             \ expects only TOS valid
    RDROP
    RDROP
    RFROM
    UNLINK

The Stundurd programmer should just assume that DUP WHILE is idiomatic and eschew OVER WHILE --- most of the time, when a processor-designer and/or compiler-writer says that some kind of code is idiomatic and another kind of code should be avoided, this means that he failed to provide adequate support for the second kind of code --- in this case, the Stundurd processor doesn't have aN OVER-NONNEG? primitive because there are only 64 primitives and we can't have everything that we want. |FIND-PRIOR isn't important enough to warrant providing a primitive just for it --- by comparison, |ITERATE and |UNTIL were important enough to provide the RFROM-LOOP? primitive just to make them more efficient --- it seems unlikely that OVER-NONNEG? would get much use in typical code, so it wasn't provided.

|FIND-PRIOR is likely the most complicated higher-order function that the brave Stundurd programmer will encounter. It is used for removing nodes from lists.

Here is our |REMOVE ( head xt -- node|FALSE new-head ) function:

: |remove  \ head xt -- node|FALSE new-head
    rover >r                                                    \ hold onto HEAD for later
    |find-prior
    dup 0< if                                                   \ it was the HEAD that we found
        r> nip                      \ -- head                   \ discard the -1
        dup @  exit then            \ -- head next-node         \ our found node is HEAD and our new-head is the next-node after that
    r> ;                            \ -- node head              \ our found node (possibly FALSE) was returned by |FIND-PRIOR and our new-head is the original head

This compiles as this:
s" |remove" header
    HUFF12
s" |remove" header21
    ROVER22
    TOR21                       \ push the head to the return-stack
    ' |FIND-PRIOR CALL
    DUP
    NONNEG?  RFROM  RETURN  ??  \ the head node was not the match, so it is still the head
    RFROM12                     \ the head node was the match, so the head will be our found node
    NIP21                       \ discard the -1
    DUP
    FETCH                       \ the new-head will be the next node after our original head (possibly a NIL if there was only one node in the list)
    RETURN

Because |REMOVE gets to have a | prefix on its name indicating the bar-feature --- this is because |REMOVE pushed its own internal data onto the return-stack while calling |FIND-PRIOR --- a bar-feature higher-order function allows the quotation to access the parent function's data-stack items.

Note that this code:
    r> nip
is more efficient than this code:
    drop r>

This is a quirk of the Stundurd instruction set, that DROP is generally less efficient than NIP. A smart optimizer should be able to be able to generate the more-efficient code even if the programmer uses the less-efficient version. Just to be on the safe side though, I hand-coded it to use the more-efficient version even though this is somewhat less readable.


section 15.) more on linked lists (pretty easy code again)

We have INIT-LIST for initializing a linked-list node.

: init-list  \ node -- node
    nil  over .fore ! ;

This compiles as:
s" init-list" header21
    PUFF21
s" init-list" header
    0 LIT12
    OVER22
    STORE21
    RETURN

Because the .FORE field is the first field in a LIST struct, we don't need to add the offset (0) to the struct address to get the field address.

For comparison, this is INIT-LIST in VFX:

see init-list
INIT-LIST
( 004C7A90    C70300000000 )          MOV       DWord Ptr 0 [EBX], 00000000
( 004C7A96    C3 )                    NEXT,
( 7 bytes, 2 instructions )

Because the 32-bit x86 is a CISC processor, we get fewer instructions but more memory usage (7 bytes compared to 4 bytes). The Stundurd is a CISC processor too, but less so than the x86. The Stundurd doesn't have instructions with complicated addressing modes that have memory addresses used as operands like the x86, although the Stundurd does have several primitives that access the data-stack or return-stack which is an implied addressing-mode. The Stundurd also has several instructions that have an immediate value as an operand, which is another addressing-mode --- for the most part though, the Stundurd is different from the x86 etc. --- the Stundurd has only one-byte and two-byte primitives, whereas most CISC processor have big complicated multi-byte instructions.

This is INIT-LIST in SwiftForth:

478F3F   4 # EBP SUB                    83ED04
478F42   EBX 0 [EBP] MOV                895D00
478F45   0 # EBX MOV                    BB00000000
478F4A   4 # EBP SUB                    83ED04
478F4D   EBX 0 [EBP] MOV                895D00
478F50   4 [EBP] EBX MOV                8B5D04
478F53   0 [EBP] EAX MOV                8B4500
478F56   EAX 0 [EBX] MOV                8903
478F58   4 [EBP] EBX MOV                8B5D04
478F5B   8 # EBP ADD                    83C508
478F5E   RET                            C3

SwiftForth isn't really doing any optimization at all; it is just inlining the 0 the OVER and the ! sub-functions into the INIT-LIST function. The author (Hugh Aguilar) recommends that nobody buy SwiftForth, as its low quality is an embarrassment to the Forth community. If you do use SwiftForth however, the novice-package has quite a lot of low-level functions (including INIT-LIST) written in assembly-language to help boost SwiftForth's abysmal speed.

As noted previously, the round-brackets ( ) are not used for comments in Stundurd (the \ is used for comments). This is because the round brackets are used for building linked-lists somewhat similar to Scheme/Lisp.

We have these words for building linked-lists:

0 constant nil

: (             \ -- head tail
    nil  nil ;

: >>            \ head tail node -- new-head new-tail
    dup 0= if  drop  exit then                                  \ NODE is nil so discard it (no need to insert nil, as the TAIL already has nil in its .FORE link)
    rover 0= if                                                 \ HEAD is nil (TAIL presumably is also nil)
        nip nip                     \ -- node                   \ discard old HEAD and TAIL that were nil
        dup                         \ -- node node              \ NODE becomes both the head and the tail
    else
        dup                         \ -- head tail node node
        rot .fore !                 \ -- head node              \ link NODE to TAIL, and leave NODE as the new TAIL
        then ;

synonym  )  >>

The right-bracket ) is just a synonym for >>. This helps readability as it indicates that the list is complete. The programmer usually puts a DROP after the right-bracket, as the tail-node is not normally needed --- the tail-node is mostly only useful for linking two lists together.

Our >> ( head tail node -- new-head new-tail ) function compiles like this:
s" >>" header
    HUFF12
s" >>" header21
    DUP-ZERO?  DROP21  RETURN  ??
    ROVER22
    PUFF21
    NONZERO?  label:1 BRANCH  ??
    NIP
    NIP
    DUP
    RETURN
1 label
    DUP12
    ROT22
    STORE21
    RETURN

As an example, lets define a list of double integers:

list
    w field .lo
    w field .hi
constant dbl

This is a child of LIST so it inherits the .FORE field. We need initializing and new'ing functions:

: init-dbl  \ n node -- node
    init-list >r
    dup             r@ .lo !
    0< negate       r@ .hi !        \ sign-extend N into the .HI field (the TRUE flag is 1, so it has to be negated to become -1)
    r> ;

: new-dbl  \ n -- node
    dbl alloc                       \ ALLOC allocates a block of memory on the heap given the size
    init-dbl ;

The reason why we have separate functions for initializing and new'ing a node, is to support inheritance. If another data type uses DBL as its parent type, it will inherit all the fields from DBL. It's initializing function should call INIT-DBL (similar to how INIT-DBL called INIT-LIST because LIST was its parent type) so the DLB fields will get initialized first, and then it will initialize its own fields.

To build a linked list of DBL nodes, we do this:

    ( 123 new-dbl >> 456 new-dbl >> 789 new-dbl ) drop

This gives us the head node of a linked list of DBL type nodes. The head has 123 in its .LO field, and the tail has 789 in its .LO field. It is possible to have nodes of different types in the same list, but it is best if they are all in the same inheritance chain.

We could also have this for an empty list:

    ( nil ) drop

This gives us NIL as the head node of a linked list.  Note that an empty ( ) is illegal, as ) expects to be given a node pointer.

Earlier we had a LENGTH ( head -- count ) function that calculated how many nodes were in a list. For improved efficiency we can get rid of the local variables and write it with stack-juggling instead:

: length  \ head -- count
    0 swap                                      \ -- count head
    begin  dup while  swap 1+ swap  .fore @  repeat drop ;

This is how it compiles:
s" length" header21
    PUFF21
s" length" header
    0 LIT12
    SWAP22
    DUP-ZERO?  DROP21  RETURN
1 label
    SWAP22
    INC22
    SWAP22
    FETCH22
    NON-ZERO?  label:1 BRANCH  ??
    DROP21
    RETURN

This is somewhat ugly, with all of that stack juggling inside of the loop. For an important function such as LENGTH, it is best to use an efficient version, even if it is ugly. The Stundurd idiom however is to use a higher-order function and give it a quotation. This usually results in the most compact code, and it is reasonably efficient --- most importantly though, it is highly readable --- this should be used for non-critical code.

Here is our LENGTH ( head -- count ) function using the Stundurd idiom:

: length  \ head -- count
    0 swap                                      \ -- count head
    { 1+ } |each ;

This compiles like this:
s" length" header21
    PUFF21
s" length" header
    0 LIT12
    SWAP22
    PUFF21
    aaa LIT             \ aaa is the cfa of the quotation
    QXT12
    ' |EACH CALL21
    RETURN

The quotation compiles as:
    INC
    RETURN

This is the most compact version of LENGTH and by far the most readable, but unfortunately the slowest. This is how Stundurd programmers should generally write their code however. The explicit iteration versions of LENGTH discussed earlier, represent non-idiomatic techniques used when speed is paramount. In general, the programmer should be more concerned about generating compact machine-code and readable source-code, in which case lambda functions are the way to go.

For the record, LENGTH was less-than straight-forward in ANS-Forth too. This is the novice-package implementation:

SwiftForth? [if]

icode length  \ head -- count
    zero(eax)
    begin  non-zero? while  [@]  eax inc  repeat
    eax ebx mov  ret end-code

[else]

: length  \ head -- count
    0 0 do
        dup 0= if  I  nip  unloop exit then
        .fore @  loop ;

[then]


section 16.) quotation security (a somewhat esoteric subject that can be ignored by most readers)

It is illegal to execute a quotation if the parent function has gone out of scope (exited). If the quotation accesses the parent function's local variables, then chaos will result, as this memory on the return-stack no longer belongs to the parent function. The memory likely holds local variables or return-addresses from some other function. The quotation will corrupt this data, but the problem won't be noticed right away --- only when that other function executes and its corrupted local variables or (worse) return-address gets used, will the problem become apparent. This would be a difficult bug to track down. That other function will be assumed to have the bug, although it had been tested already and found to be okay --- the programmer would have a difficult time tracking when and how the data got corrupted.

It is possible to prevent quotations from executing after the parent function has gone out of scope. The parent function has to have a security-local as its last local variable, and this contains the quotation's address. If there is more than one quotation in the parent function, then there will be that many security-locals, each corresponding to a quotation. When the parent function goes out of scope (just prior to its UNLINK instruction), it zeros out the security-local(s). When the quotation executes, it first tests its security-local in the parent function's local-frame to determine that it contains its own address, in which case the parent function is assumed to still be in scope and everything is cool. If the security-local has any other value, then the quotation knows that the parent function has gone out of scope and it aborts. So, we get an abort at a time when the abort will make sense to the programmer and he can fix the bug --- this is much better than subtly corrupting another function's return-stack data so the system goes haywire at a later time leaving no clues as to when or how it got corrupted.

We can't have false-positives; if the security-local doesn't contain the quotation's address, then we are certain that the parent function has gone out of scope. We can have false-negatives however; it is possible that the parent function has gone out of scope and by bad luck some other function has a local-variable datum that happens to be the same as the quotation's address, and happens to be in the same memory location that the quotation is expecting to find its security-local. If the data in the return-stack (where the security-local pointer is pointing) is random, then the chance of a false-negative is 1/65536. Actually though, most of the data in the return-stack are return-addresses and these can't be the same as the quotation address. Also, all the local variables in the return-stack are double-cell; the high word is typically 0 or -1, so it can't be the same as the quotation address. All in all, the chance of a false-negative is maybe one in a million --- so, getting a false-negative would be remarkably unlucky even by programmer standards (programmers tend to be unlucky people).

For security, we need these two functions:

s" clear-security" header   ( index -- )            \ the index is of the security-local
    LOCAL
    0 LIT12
    SWAP22
    STORE21
    RETURN

s" test-security" header21  ( aaa index -- )        \ aaa is the quotation address, and the index is of the security-local
    LOCAL22
    FETCH22
    NEG22
    PLUS21                                          \ aaa minus the contents of the security-local (should be zero, as they are supposed to be the same)
    NONZERO?  ' QUIT  CALL  ??                      \ this dumps the programmer into the debugger, where he can determine which quotation aborted
    RETURN

These two functions are not available to the programmer. in general, it is illegal for a sub-function to access the local variables of the calling function, as these two functions do (normally the calling function would pass in the address of its local-variable rather than the index, but doing that here would result in every quotation being bloated out by the LOCAL instruction). When security is turned on, the cross-compiler automatically compiles them as needed.

Here once again is our example code:

list
    d field .name$      \ employee name
    d field .salary     \ salary per year in dollars
    c field .female?    \ flag indicating gender
constant employee

: count-females  local{ employee-head | cnt -- females }     \ EMPLOYEE-HEAD is the head of a LIST linked list
    employee-head @  { .female? c@  cnt +! }  each
    cnt @ ;

With security turned on, this is how the COUNT-FEMALES colon word gets compiled:
s" count-females" header21
    PUFF21
s" count-females" header
    LINK
    ZERO-LOCAL              \ this initializes CNT
    INIT-LOCAL              \ this initializes EMPLOYEE-HEAD
    aaa LIT                 \ aaa is the cfa of our quotation
    INIT-LOCAL              \ this is the security-local
    1 LIT
    LOCAL                   \ this is EMPLOYEE-HEAD
    FETCH
    aaa LIT                 \ aaa is the cfa of our quotation
    QXT12
    ' EACH CALL21
    2 LIT
    LOCAL                   \ this is CNT
    FETCH
    3 LIT                   \ this is the index of the security-local
    ' CLEAR-SECURITY CALL   \ clear our security-local to indicate to our quotation that COUNT-FEMALES has gone out of scope
    UNLINK

With security turned on, this is how the quotation gets compiled:
    QLINK
    aaa LIT                 \ this is the cfa of this quotation
    3 LIT12                 \ this is the index of the security-local
    ' TEST-SECURITY CALL21  \ test the security-local to make sure that the parent function (COUNT-FEMALES) is still in scope
    .female? LIT-PLUS
    CFETCH
    2 LOCAL12               \ this is CNT
    PLUS-STORE21
    QUNLINK

The COUNT-FEMALES function had only one quotation inside of it, and so there was only one security-local. If there had been several quotations, then we would have needed one security-local for each quotation. Each quotation would need to use the correct index of the security-local that corresponds to it. All of this information is known at compile-time, so it is easy for the cross-compiler to compile the parent-function and quotation(s) correctly.

When security is turned on, the cross-compiler compiles some extra code in the parent function and in its quotation(s). At run-time, this code will ensure that the quotation doesn't execute after the parent function has exited. The parent function and quotation come out slightly bloated and slow compared to the unsecure versions. Because of this bloat and drop in speed, security should not be turned on for the production version of a program, but only for the testing versions. The programmer should also not turn security on for the entire program, but only for portions of the program. For the most part, it should be easy for the programmer to know a-priori that his quotations aren't being executed after the parent function has gone out of scope. In COUNT-FEMALES for example, the quotation's xt is given to EACH and EACH consumes it, so the quotation can't execute after COUNT-FEMALES has exited; we don't really need security testing with such a simple use of a quotation. Security is primarily an issue if quotation xt values are being stored in data-structures and then executed later on. This is not commonly done, so security is generally a non-problem. Only if the programmer is doing some complicated machinations with his quotations does security become an issue --- then the above-described security feature of the cross-compiler can be used to make sure that the programmer isn't being too clever for his own good.


section 16.5) TSR (Terminate-and-Stay-Resident) functions

It is possible to define a word with TSR: rather than : and have the local-frame of the word remain valid after the word has exited. A TSR is the same as a colon word except that the local-frame is allocated on the heap rather than on the return-stack.

The idea is that the TSR contains a quotation, and returns the xt values for that quotation (called a "generator," which is a term borrowed from the Icon language). When a generator is executed after the TSR has exited, the local-frame of the TSR is still valid. This is essentially a weak form of OOP --- the local-frame is the object with the local variables being the fields, the TSR is the constructor, and the generator is a method. It is possible for the TSR to return more than one generator xt, in which case all of them are different methods. It is a hassle to have more than one xt returned though, and so it is best to write TSRs that only return one generator. Stundurd Forth does have an OOP facility (the same as in the novice-package) that allows for multiple named methods and inheritance (but not polymorphism), and this should generally be used for data-structures. TSRs not only lack inheritance, but TSRs also lack a mechanism for cloning the object, which the OOP facility has. In general, the OOP facility should be used for all data-structures.

TSRs can be used as an adjunct to the OOP facility. The local-frame of the TSR would contain a pointer to the data-structure as well as some other information about the data-structure. The generator that the TSR returns will, when executed, traverse the data-structure until it matches some kind of pattern in one of the elements of the data-structure, at which time it will return a pointer to that element (or some kind of representation of the element). The generator can be executed more than once, and each search will start up where the last search left off, rather than always start at the beginning of the data-structure. So, the generator on successive calls generates every element that matches the pattern (that is why it is called a "generator").

As a simple example, we might have a TSR called SPLIT$ that works with strings. The generator that it returns is used for splitting a string around deliminators; it returns either a string (the substring up to the deliminator but not including the deliminator), or it returns the whole string if there was no delimitor found, or it returns FALSE (0) if the string given to it was empty. Each time the generator is executed it starts over from just past the previous match. The following is an example of how SPLIT$ could be used:

: type-fields  \ adr:cnt -- 
    [char] ,  [char] <  [char] >  split$ >r                     \ --        \r: -- xt
    begin  r@ execute  dup while  cr  count type  repeat drop
    r> kill-split$ ;
    
If the string "<Aguilar, Hugh>, 49, programmer" were given to TYPE-FIELDS then the following would by typed out:
Aguilar, Hugh
49
programmer

When SPLIT$ is called, it takes four parameters. First we have the adr:cnt of the string (this is actually two elements on the stack), then we have the delimitor char, then we have the left-bracket char for the excluded part, then we have the right-bracket char for the excluded part. Whenever a programmer writes a TSR he also needs to write a generator-killer for that TSR. In this case, we have KILL-SPLIT$ that kills the generator that SPLIT$ provided. The generator-killer should deallocate any pointers to heap memory-blocks that may be in the TSR's local-frame (in this case, the pointer to the string), and it should also deallocate the local-frame. Stundurd Forth doesn't have garbage-collection, so any generator created by a TSR has to be explicitly killed by the generator-killer that is associated with that TSR --- otherwise there would be a memory leak.

SPLIT$ is similar to SPLIT that was in the novice-package. SPLIT$ is more robust however because it provides each substring to the programmer one at a time and the programmer can do what he wants with them (in this case, just type them out). By comparison, SPLIT always returned a linked-list of the substrings. With SPLIT$ the programmer can put the substrings in a linked-list if he wants to, but it is up to him.

Generators don't really provide any functionality that couldn't be done just using the basic OOP facility, and in many cases they aren't able to provide functionality that could be done using the basic OOP facility. Generators are a convenience --- they allow the source-code to be less bloated and more easy to read in certain simple cases such as string pattern-matching.

A TSR is similar to a <BUILDS DOES> definer except that it builds its struct at run-time rather than compile-time and it puts it in the heap rather than the dictionary, and also the generator doesn't have a name in the dictionary. TSRs can do everything that <BUILDS DOES> definers can do and TSRs are the idiom in Stundurd Forth. <BUILDS DOES> is provided primarily to support porting legacy Forth code over to Stundurd Forth. In ANS-Forth it is called CREATE DOES> rather than <BUILDS DOES>, but it is easy to port ANS-Forth code over to Stundurd just by changing CREATE into <BUILDS whenever there is an associated DOES> but not when CREATE is used without a DOES>.


section 17.) quotations and lambda functions (some controversial thoughts on theory)

This section has been criticized on the basis that denouncing ANS-Forth and Forth-200x will push people away from Stundurd Forth if they are on the fence about whether they like ANS-Forth and Forth-200x or not. This isn't really a concern however, because very few people in the world (less than 20) like ANS-Forth and Forth-200x. This is about the same number of people as were in the Heaven's Gate cult during its heyday. Nobody is sitting on the fence in regard to either ANS-Forth or Heaven's Gate. This section could still be considered pointless however, because almost nobody in the world has heard of Forth --- this is like how denouncing Heaven's Gate was pretty pointless during its heyday, as less than one in a million would hear of Heaven's Gate otherwise (Heaven's Gate only became widely known after it concluded). When the author claims to be a Forth programmer, the typical programmer with a degree and a job thinks that the author is mispronouncing "Fortran" --- people routinely go through a computer-science major without ever hearing about Forth in their school studies. Fortran is considered to be an obsolete language and Fortran is discussed in regard as to why it became obsolete (the functions weren't reentrant), but Forth isn't considered to be important enough to discuss. Forth aspires to be obsolete, which would be a big step up from being nonexistent! This is despite the fact that in 1985 Forth was considered to be more likely than C to become the language of personal-computers, as C was still unavailable on personal-computers and was entirely associated with Unix($$$), whereas Forth was already widely available on personal-computers. In 2015 however, the Forth community is still stuck in 1985 talking about Forth's potential. Now the only way that people might bump into Forth is in their personal studies --- goofing around on the internet listening to the VCIW (voices crying in the wilderness). The fact that a person is reading this document however, implies that the person already knows what Forth is (this is not an entry-level document like "Starting Forth" with its cartoons). If the reader already knows about Forth however, then the reader almost certainly comes to this document burdened by one of the following misconceptions about Forth:

1.) The Forth community believes that :NONAME with some syntactic sugar is a quotation, despite the fact that :NONAME functions do not have access to the parent function's local variables (they don't actually have a parent function).
2.) Introducing lambda functions into Forth involves tagged data (dynamic-OOP) and garbage-collection, which would make Forth far too inefficient to be used in a micro-controller (inefficiency is the reason why Lisp doesn't get used).
3.) The Forth community believes that reusable code is an archive of old programs that can be cut-and-pasted into new programs, and that the data-structure algorithms have to be customized for the application every time. Forth can't have code libraries because the functions aren't reentrant, but the Forth community believes that reentrancy is a "mythical dragon" that they can ignore.
4.) C is the "god language" that does everything that a programming language could do, and in the most efficient way possible --- gForth is an amusing toy interpreter written in C that is useful for learning C but which doesn't have any more practical value than a Sudoku solver --- writing programs in Forth is a waste of time comparable to solving Sudoku puzzles by pencil-and-paper, so it is best to just focus on the internal workings of gForth so that one may learn some C programming techniques.

If Stundurd Forth is going to be accepted, then it is imperative that these false ideas be dispelled! The greatest danger is that people will say: "I heard that Stundurd Forth is just like Standard Forth but a little better, however I didn't bother to read about it because ANS-Forth is a total failure --- Forth is fundamentally flawed, so until the Forth programmers learn the basic concepts of computer-science they will continue to be total failures." ANS-Forth was just a marketing gimmick from Elizabeth Rather intended to convince the world that Forth Inc. sets the standard for all Forth programmers --- but the black mark of ANS-Forth will out-live Elizabeth Rather and Forth Inc. --- the profound failure of ANS-Forth will continue to stain the Forth language throughout the 21st century and well into the 22nd century. The Forth community can never wash off the black mark of Standard Forth, but by changing the name to Stundurd Forth they can acknowledge the black mark that they bear. Just because the Forth community has a black mark that they can't wash off, doesn't obligate them to embrace the darkness --- instead they can allow the sun to shine on their black mark, and perhaps in 100 or 200 years it will fade away.

As an example of the typical attitude toward Forth, I got only one response to my mention of the FMITE processor (now called the Stundurd processor) on this forum:
https://embdev.net/topic/370139

---------------------------------------------------------------------------
Looks like pure academic fun to me.
But you don't seriously expect us to fully read and understand your
entire text file, do you?
We do share a lot of academic fun, but I guess you'll have to a wee bit
of 'marketing' and tell us what your processor is good at.
Bytecode stuff is interesting, but eventually people will care about
robustness and how easy they can achieve their goal. Programming aspects
DO count, and you'll get very little attention from the industry by
using Forth..
---------------------------------------------------------------------------

This attitude toward Forth is the result of ANS-Forth being the "Standard Forth" --- ANS-Forth totally ruined Forth's reputation because it lacked robustness and it made achieving goals far more difficult than necessary, and consequently for over 20 years now people have felt justified in simply ignoring anything having to do with Forth --- if the "Standard Forth" is stupid, then there is no need to bother examining the wanna-be Forths as they can be dismissed off-hand as being below stupid. It is primarily the misconceptions listed above (mostly #3) that bring on such a negative response to any mention of Forth. ANS-Forth became Standard Forth in 1994, and it was in 1995 that the MiniForth went into production in Testra's motion-control boards. At that time, everybody was talking about ANS-Forth, and what they were saying was: "Goodbye to Forth and hello to C." ANS-Forth was stupid on every level; nobody wanted it, and there was no ANS-Forth compiler available anyway so it was all just "pure academic fun" (SwiftForth would be the first ANS-Forth compiler; it wouldn't come out until 1997, at which time it would be found to be grossly over-priced and so bug-ridden as to be completely useless). In 1995, it was impossible to talk about the MiniForth, because any such success was completely over-shadowed by the failure of ANS-Forth --- Forth got very little attention from the industry after 1994 --- all Forth programmers became damned forever, in so much as they were blamed for ANS-Forth and they can never be forgiven for ANS-Forth, even though they had not been personally involved in perpetrating ANS-Forth.

This section is intended to address misconceptions #1, #2 and #3 above. If the reader believes one or more of these, then he should read this section to hopefully be disabused of his error. If the reader doesn't believe #1, #2 or #3, then he can skip this section (it is pretty lengthy). If the reader believes #4 then there is really nothing to be done to undeceive him on C's wonderfulness because he isn't going to read any document that isn't about C --- proffering this document to the #4 believers is going to work about as well as handing out vegan cookbooks in a hunting lodge --- there is still hope for those in the #1, #2 or #3 categories however.

Category #1.)

Forth-200x has "quotations" (so called by Bernd Payson the implementer), but they aren't really quotations because they don't have access to the parent function's local variables (they are just :NONAME with some syntactic sugar). They lack the ability to access the parent function's local variables. They can access the data-stack, but this is very inefficient because Forth-200x an efficient way to execute an xt in a local variable, so there is no good place to hold the xt aside temporarily while using >R to push the internal data onto the return-stack. The only higher-order function that has ever been written in Forth-200x, was TRAVERSE-WORDLIST --- this example gets trotted out every time than anybody (me) complains that Forth-200x lacks support for lambda-functions and higher-order functions. Similarly, QSORT is the only higher-order function available in C, and this example gets trotted out every time than anybody (me) complains that C lacks support for lambda-functions and higher-order functions. As a practical matter though, both Forth-200x and C do lack support for lambda-functions and higher-order functions. By comparison, in Stundurd Forth, lambda-functions and higher-order functions are idiomatic and efficient.

Bernd Payson is on the Forth-200x committee. He is also the perpetrator of "quotations" that are just :NONAME faked up as quotations, and he made this part of the Forth-200x "standard" (the word "quotations" is in scare-quotes because the Forth-200x quotations aren't quotations, and the word "standard" is in scare-quotes because Forth-200x isn't standard anywhere). The primary result of Forth-200x is that programmers in the real-world are led to believe that nobody in the Forth community knows what quotations are and that all of us are just faking it. The Stundurd processor is largely a response to Forth-200x and its bogus quotations --- Stundurd was made public to prove that at least one Forth programmer in the world knows what quotations are. The author (Hugh Aguilar) recommends that nobody use Forth-200x at all, because doing so puts a black mark on the entire Forth community --- nobody will ever take any version of Forth seriously if the "standard" Forth is founded upon fakery and hand-waving; people won't look past Forth-200x. This is what happened in 1994; ANS-Forth put a black mark on the entire Forth community causing professional Forth systems such as UR/Forth to die out, although they weren't ANS-Forth and hence were blameless. In 1993, Ray Duncan the vendor of UR/Forth was describing ANS-Forth as "brain-damaged" on comp.lang.forth; In 1994 ANS-Forth came out (with Ray Duncan listed in the document as a contributor), and Ray Duncan gave up on Forth completely (his company, Laboratory Microsystems Inc. folded). The author's only experience as a professional Forth programmer was with UR/Forth, but after ANS-Forth came out the Forth language largely died and there was no more work available. Now, 20 years later, the same people who were guilty of the ANS-Forth fiasco, have self-elected themselves to the Forth-200x committee --- they are once again building a castle on the sand, because they still aren't familiar with the bedrock of computer-science (they don't know what lambda functions are) --- they really don't deserve any credence whatsoever, as their goal in life is to drag every Forther down to their own level of ignorance and call it "Standard." It is the author's hope that Stundurd Forth should displace Standard Forth (ANS-Forth and now Forth-200x) in the 16-bit micro-controller world --- Stundurd Forth is a thinking-person's Forth --- the self-proclaimed "standard" Forths are for non-thinking people whose only aspiration is to be Standard with a capital 'S' (woo hoo!).

Category #2.)

The term "lambda function" has been popularized by the Lisp/Scheme crowd. The Lispers' fundamental book on computer-science, "Structure and Interpretation of Computer Programs," has the lambda symbol prominently displayed on the cover, so the concept is obviously dear (perhaps even holy) to them. A Greek-letter was chosen to represent the concept for the purpose of giving it a quasi-mathematical aspect, as if the Lispers are in the same league as Leibniz and Newton inventing calculus (get real! it is just programming!). Lambda functions were invented by Alonzo Church as an abstract mathematical concept, but the fly in the ointment was that in the real world they can't persist forever (as they do in the abstract ideal) and they have to be garbage-collected eventually, but garbage-collection is a no-go in a real-time micro-controller. The Lispers' lambda functions have proven to be inefficient, and so Lisp/Scheme yet languish in the ivory tower and have never made any headway out into the real-world. Some Lisp derivatives such as Python and Ruby are popular, but they are only used as scripting languages and/or web-server languages and are notoriously inefficient. Lisp and its derivatives have never been competitive with C++ (the world's ugliest programming language) in the desktop-computer world. Java is another screwed-up language that isn't competitive with C++, but for different reasons that we won't get into here.

Verily, the Lispers over-complicated the subject of lambda functions for no purpose, which is why Lisp has never been used much outside of academia. Their functions store the local-frame in the heap, and this local-frame has to be garbage-collected. They do this so the lambda function that is accessing this local-frame can continue to be usable after the parent function has gone out of scope (exited). The local-frame has to be garbage-collected after the parent function and any lambda-functions that it spawned (there may be multiple pointers to the same lambda function stashed in various data-structures) have all gone out of scope --- unfortunately, garbage-collection is complicated and inefficient --- no real-time micro-controller will ever have a garbage-collected heap, because this is too slow, and it is too difficult to predict how slow it is (the system tends to stutter). The Lisp technique is a solution to a non-problem though! There is no good reason to execute a lambda function after the parent function has gone out of scope. It is much more efficient to do what Stundurd does, which is store the local-frame on the return-stack and discard it (with UNLINK) when the parent function goes out of scope. In Stundurd, the quotation is not supposed to be executed after the parent function has gone out of scope. If the programmer wants an anonymous function that is usable indefinitely, he can define it with :NONAME --- this is almost never needed however (the author can't recall having ever used :NONAME for anything in his many years of Forth programming).

In summary, there are three kinds of anonymous functions:
1.) :NONAME functions --- these are just like colon words, except that they don't have a name. They are almost totally useless because they don't provide a means to communicate with the parent function (they don't really have a parent function). :NONAME functions are not a kind of lambda function.
2.) quotations --- these are what Stundurd provides. These have access to the parent function's local variables, which is the idiomatic method of communicating with the parent function. If a bar-feature higher-order function is used to call a quotation, then the quotation also has access to the parent function's data-stack, which can be more convenient. Quotations are a kind of lambda function.
3.) lambda functions --- these are what Scheme, Lisp, and myriad derivative languages provide. These are like quotations except with the extra feature that they can persist indefinitely (after the parent function has gone out of scope) similar to :NONAME functions.

#2 above is the Goldilocks solution. :NONAME as provided in ANS-Forth and Forth-200x is too small of a bowl, empty of features. #3 as provided in Scheme, Lisp, etc., is too big of a bowl, full of an unneeded feature. #2 as provided in Stundurd Forth is the bowl that is just right, as it allows for general-purpose data-structures (such as our linked lists discussed in this article), while yet being efficient enough to be implemented in an FPGA that would be used as a low-cost micro-controller.

The Lispers are rock-solid on #3 however, and they apparently believe that it is efficient to do garbage-collection on a real-time micro-controller. In this thread I brought up my FMITE design (now called Stundurd): https://groups.google.com/forum/#!searchin/comp.lang.lisp/fmite/comp.lang.lisp/-nWfXAs_4ug/moiaKx78CPsJ
This was the response:
On Thursday, July 2, 2015 at 1:06:22 AM UTC-7, informatimago wrote:
> hughaguilar96@gmail.com writes:
>
> > On Tuesday, June 30, 2015 at 11:59:44 PM UTC-7, informatimago wrote:
> >> hughaguilar96@gmail.com writes:
> >> > AFAIK, I'm the only person attempting to bring lambda functions to
> >> > micro-controllers. Certainly, GC is a no-go in a real-time system no
> >> > matter how fast the processor is, because GC causes stuttering and
> >> > hence it is not possible to ensure that code executes in the time
> >> > allotted to it.
> >>
> >> Nonetheless, you need to learn more. Much more!
> >
> > My background is that I wrote MFX, the Forth cross-compiler, assembler and simulator for this processor:
> > http://www.testra.com/Forth/RACE.htm
> > Because of this experience, I know something about what can be done in
> > a custom processor (the MiniForth was built on a Lattice isp1048 PLD).
> >
> >> There are a lot of real-time GC algorithms (and even parallel and
> >> multi-threaded GC algorithms), that are able to collect garbage with no
> >> pause ever.
> >
> > Multi-threading doesn't prevent pauses --- multi-threading is all
> > about pausing (that is why they have a PAUSE command for switching
> > tasks). As for parallel-processing (presumably with dual-port memory),
> > that is way out of my league --- I'm just designing a
> > micro-controller.
>
> Of course. That's why, if you're smart, you will ignore the
> parenthetical mention of multi-threaded GC algorithms, and use instead
> the real-time, pauseless GC algorithms!
>
> > All in all, I think you are beating me up for not bringing
> > desktop-computer programming to the micro-controller that is
> > unrealistic
>
> No. I'm beating you up for not using google for:
>    real-time garbage collector
> or pauseless garbage collector
> or hardware garbage collector
> and coming here telling us that "GC is a no-go in a real-time system".
>
> --
> __Pascal Bourguignon__                 http://www.informatimago.com/
> The factory of the future will have only two employees, a man and a
> dog. The man will be there to feed the dog. The dog will be there to
> keep the man from touching the equipment. -- Carl Bass CEO Autodesk

The Stundurd is an upgrade to the FMITE in that it does provide support for a dual-core system with dual-ported memory (it has the WEXCH-GP instruction for working with a semaphore that would reperesent possession of the common-memory). Still though, even given a dual-core system, garbage-collection is a no-go. It is a huge waste of resources to dedicate a core solely to garbage-collection, and it is still going to slow down the main program unbearably to have the coprocessor periodically taking possession of the common-memory (and it is going to require a gigantic common-memory region). Given a dual-core system, the most efficient scheme would be to have the main program in one core and all the I/O access in the other core --- this is a micro-controller after all, and I/O access is what micro-controllers spend most of their time doing --- the goal of Stundurd programmers is to graduate from C to a language that supports general-purpose data-structures. Our goal is not to join the Lispers with their heads in the clouds, but rather to keep our feet on the ground and write programs that are competitive($$$) in the real world.

Mr. Bourguignon is living in a fantasy world --- Lisp is uneconomical for real-time micro-controllers in the real world. Maybe garbage-collection could be done in real-time in an expensive multi-core system --- if the real-time constraints were lenient --- but if the real-time constraints are that lenient then why not just use an 8-bit processor such as the AVR and program in C or traditional Forth? But, from the perspective of the ivory-tower where the Lispers live, Lisp is the perfect solution to real-time micro-controllers --- nevermind that almost all real-time micro-controllers are programmed in C, and less than 5% are programmed in BASIC, Forth, assembly-language, etc., and none are programmed in Lisp --- but anybody who disagrees with the Lisp pontificators gets a beating!

The Stundurd is a micro-controller design (it supports only 32KB of RAM maximum and is intended to be built into a low-cost FPGA). The quotation concept used in Stundurd Forth could be used in a desktop-computer language also though. The author may do this in the future. Right now, the author is focusing on micro-controllers because that is where the money is (desktop-computer programs are almost always given away for free under the GNU public-license, so there is not much point in worrying about what language they are written in).

Category #3.)

The purpose of quotations is to make general-purpose data-structures feasible. We have higher-order functions that iterate through a data-structure and they apply the quotation to every node. EACH can iterate through a singly-linked list. Forth has traditionally not had general-purpose data-structures. If people needed a linked-list, they manually wrote the BEGIN WHILE REPEAT loop every time that they needed to traverse the list, and all of this code was quite similar. Also, if a person needed a more complicated data-structure such as a self-balancing binary-tree and he didn't have the time to figure out the algorithm, he would find another program somewhere that had what he wanted and he would cut-and-paste that code into his program without really understanding it. It is much better to use a code library however, because the implementation is hidden and only the behavior is exposed, so it is not necessary to understand the implementation (algorithm) but it is only necessary to understand the behavior. By comparison, with cut-and-paste the programmer has the implementation fully exposed in his program and he doesn't understand it. The author (Hugh Aguilar) worked as an IBM370 assembly-language programmer for a couple of years. Most of the "programmers" in the mainframe world are actually computer-operators (tape-monkees) who got promoted to programmer, but they don't know much about computer-science. They rely heavily on cut-and-paste. A program, presumably written by a real programmer originally (often just a one-day effort that he did under deadline), may be modified many dozens of times resulting in many dozens of programs that are all quite similar but subtly different (and the differences are not well documented). After a while, it often happens that nobody remembers which is the original version, so they are making copies of copies. This results in low-quality software, but it allows people who don't really know how to program to be programmers. This also results in a corrupt work environment. The FNG (F'ing New Guy) is not given access to the archive of old programs held by the FOD (Foul Old Dude). When the boss asks for a program to be written, he can expect the FOD to finish it in a day or two because it is very similar to another program already written. By comparison, the FNG may take a week or two because he has to write it from scratch (in most cases, the FNG can't use a code library that he downloaded from the internet because it hasn't been approved for the work-place). So, the FNG is put in the awkward position of having to ask the FOD for access to the similar program in the archive, which usually requires some brown-nosing. The mainframe world is all about bullying and brown-nosing --- some people just gravitate toward this culture. The author has also worked as a machinist, and it is the same there in regard to gcode programs for CNC machines. The reason there is a similarity is that both COBOL and gcode are languages that don't support general-purpose data-structures and reusable code. Modern languages encourage the development of code libraries.

Elizabeth Rather:           Since it's so easy to write common procedures in Forth, they tend to be tightly adapted to the application for which they're developed,
                            which makes them less amenable to sharing.

Anton Ertl question:        Why do other languages have a thriving culture of sharing reusable code and Forth doesn't? One of the reasons is that the idea of code
                            reuse is despised by a significant part of the Forth community, according to lore starting with Charles Moore.

Elizabeth Rather response:  That is not entirely true. Chuck carried around with him a large library of things he had written in the past (in the 70's, a notebook
                            full of microfiches and a reader!), and always started with past code when he could. Of course, then he re-wrote it for the application
                            at hand (see my last point above). And everyone I know who is spending a career writing Forth applications has a bulging "back pocket"
                            of reusable code. FORTH, Inc., MPE, and probably most other widely used systems have such libraries.

What Elizabeth Rather is describing --- the bulging "back pocket" --- is not a code library (despite her calling it a "library"); this is an archive of old programs. In the COBOL or CNC culture, if the FNG writes a program from scratch, the boss will reject it because: "that is not the way that we write that kind of program around here." The boss will ask how the FNG can be sure that the program works if it hasn't been previously used dozens of times and didn't come from a reliable source. The boss will accuse the FNG of being a smart-aleck and brashly claiming that he knows more about the job than the old-timers who have been doing the job for years. Essentially, the FNG is required to cut-and-paste old programs and isn't authorized to write original programs, although he will be promised that after a few years when he has proven himself he will gradually be allowed to write programs that aren't cut-and-paste of existing programs. In the meantime, he will cut-and-paste old programs from the archive, and his learning curve will primarily involve familiarizing himself with the archive (the archive never has any documentation, so this familiarization will take years) --- if he is not allowed access to the archive, then he will have to politely ask the FOD to give him copies of appropriate programs from the archive as needed, and he will save them in his own archive so he can gradually replicate the archive. The system is designed so that the transition from FNG to FOD will take several years of brown-nosing.

The FOD/FNG system was prevalent during the Middle Ages when European technology was based on trade-guilds and apprenticeships --- during the Middle Ages it was mostly chemical engineering (the formulas and recipes) that were kept in the journeyman's bulging back-pocket. The science of chemistry didn't exist in the sense that a young person could learn chemistry outside of the context of any particular trade (different trades used different terminology for the same things, and when they had common words such as "acid" they didn't have any means of comparison such as the PH-scale). During the Middle Ages, there was a lot of hostility toward the concept of science. The thinking of the time was that science was totally impractical and that the trades were pragmatic. Science is focused on acquiring general-purpose information and sharing it, whereas the trade guilds were focused on acquiring trade-specific information and hoarding it. The trade guilds were focused on the past, in the sense that information obtained in the past was valuable and would be replicated throughout the future (essentially, cut-and-paste programming). The proto-scientists were focused on the future, in the sense that concepts learned in the past could be the foundation for more learning in the future. The following is a quote from Elizabeth Rather that sounds like something a journeyman representing a 17th-century trade guild might have said, as it perfectly illustrates the tension of the Middle Ages between the trade-guilds and science:

Elizabeth Rather quote #1:  I have observed that there are programmers who occupy themselves with building shinier and shinier tools, and others who spend their
                            time actually making applications work. The latter have a pragmatic, not theoretical, view of what tools are valuable and what are not,
                            and their toolkit tends to be quite different.

To be fair, there are "programmers" who can't program, so they spend a lot of time on the internet criticizing programmers for their choice of algorithms. Also, if they have a job programming they gravitate toward vague tool-building assignments that don't have deadlines. If they get put in the awkward position of having to write a program on deadline, which they aren't capable of doing, they blame their tools when they fail. Every programming language is plagued with dead weight such as this, and Stundurd Forth won't be immune, but this doesn't matter so long as the Stundurd micro-controller is considered to be competitive with the C-centric micro-controllers at a practical level. The important point, is that in Stundurd Forth we have general-purpose reusable code libraries available. Obviously, people who are capable of programming, rather than the fakers, should be the ones who write these toolkits (mostly just myself initially). But, no matter how capable the programmers are, if the language doesn't have quotations (ANS-Forth, Forth-200x and C do not) then the programmers will be hamstrung in their effort to build a toolkit. Quotations are essential to actually having a toolkit at all.

The "toolkit" that Elizabeth Rather is referring to, that "tends to be quite different," is actually just an archive of past programs that can be cut-and-pasted into future programs. The behavior and implementation is mixed together and largely inseparable, so there is no way to think abstractly about programming as a science. This was really the hallmark of the Middle Ages --- people didn't abstractify very well --- what we now consider to be autism was the zeitgeist of the Middle Ages (see any of Temple Grandin's books for a discussion of abstractification and autism). Rituals were very important during the Middle Ages, because they allowed people to think about abstract concepts in concrete terms. For example, when a man committed to being a vassal to a lord, he would he hold his hand out and give a ritual speech about how he would not move his hand without his lord telling him to do so, and the lord would grasp his wrist implying control --- people needed rituals like this to concretify concepts in their minds. Even today many people rely heavily on rituals to help them get a grip on reality (for example: pointing and clicking in a GUI). Our supposed modern era has not progressed much from the Middle Ages, and since the advent of computers we have gone more backwards than forwards (if we continue back-sliding, the much-anticipated post-modern era will be remarkably similar to the Middle Ages that we supposedly left behind). People weren't doing much abstract thinking in the Middle Ages, and they aren't doing a lot now either. There is very little writing from the Middle Ages that goes beyond purely day-to-day thinking and gives any perspective on the big picture. This was also the paradigm of the trade guilds --- they focused entirely on day-to-day work, which was just a replication of past work, but they didn't give any thought to the future in the sense that they were learning any new concepts that would change anything --- the apprentices were also expected to follow in their masters' footsteps as replicants of their masters.

The good thing about a code library is that only the behavior of a container needs to be understood by the user, but all the complicated implementation details are hidden. Also, the API (Application Programmer Interface) can be documented, but old COBOL or gcode programs have little or no documentation, and there is no good way to separate the behavior from the implementation because the code is all mixed together in the program. So, if Forth is going to ever succeed as a professional programming language, we need to get away from COBOL-style programming (which is really the same as trade-guild thinking) and start building programs based on reusable code libraries (empower the FNGs!). Unfortunately, ANS-Forth is designed entirely around COBOL-style programming. To understand how it became like this, we need to read some quotes from Elizabeth Rather (chair-person of the ANS-Forth committee). ANS-Forth totally embodies Elizabeth Rather's understanding of computer programming, so to understand idiomatic ANS-Forth it is only necessary to understand where Elizabeth Rather is coming from.

Elizabeth Rather quote #2:  Truly, I don't see the point of all this paranoia about reentrancy, particularly in systems without a multitasker. VARIABLE was *designed*
                            for things that would be used in multiple definitions. I remember the horror of (*gasp*) global variables back in the 1960's in Fortran.
                            But, frankly, in 30+ years of programming in Forth I never found them a problem. I think this is all about mythical dragons.

Elizabeth Rather quote #3:  In 1971-2 I managed a group of COBOL programmers and wrote a fair amt of COBOL myself. Yes, it was an interesting learning experience!

Elizabeth Rather quote #4:  I hate locals :-)

Elizabeth Rather quote #5:  I'd actually be grateful for a simple English explanation of what "quotations" are, as I've heard the term used in various ways in this
                            context [general-purpose data-structures], and have never seen an explanation that isn't along the lines of, "Well, this is how {whatever}
                            does it..."

Elizabeth Rather quote #6:  Does "*every* application" you write use exactly the same kind of data arranged in the same way? If so, having written it once you can
                            reuse it often. If not, you either have to rearrange your data to make it work or modify your "general-purpose" structure.

Quote #6 above is why I abandoned the Forth-200x effort. The "you" she is referring to is myself. She is telling everybody that the general-purpose data-structures that I wrote in my novice-package (specifically, LIST.4TH and ASSOCIATION.4TH) have to be modified with every application program to fit that program's unique data. It was also at this time that quote #1 came about, in which she accused me of "building shinier and shinier tools" and of not being capable of writing programs that work (she claimed that I was fired from Testra, that my MFX didn't work, and that the MiniForth processor didn't work, all of which was untrue). I had to either agree with her or leave --- I wasn't willing to accept the required level of incompetence, so I abandoned Forth-200x --- I don't think that Forth-200x will succeed so long as the committee remain vassals of Forth Inc. (Forth-200x is mandated to be 100% compatible with ANS-Forth).

There are hundreds more similar quotes in comp.lang.forth --- everything that Elizabeth Rather says about Forth reeks of COBOL --- she tirelessly denounces reusable code on the basis that a programmer should hand-write every line of code so he can make his program super-optimized. Phrases such as "full control" and "look at the whole application" imply that the programmer has source-code to his entire program, meaning that there are no code libraries written by other people, and furthermore that his entire program is small enough that he can mentally keep track of which functions use which global variables (see quote #1 above about how global variables are designed for passing parameters between functions). Here are some more quotes (denouncing reusable code is her hobby-horse, so it is no exaggeration to say that there are hundreds of quotes like this):

Elizabeth Rather quote #7:  ...in Forth it's so easy to build data structures that are exactly right for the particular application at hand that worrying about what
                            pre-built structures you have and how to use them is just not worth the bother.

Elizabeth Rather quote #8:  People are much too phobic about [global] variables. The cry, "They aren't re-entrant" simply means you have to look at the whole
                            application and how it is organized.

Elizabeth Rather quote #9:  ...in applications where you *do* want to do range checking [of array indices], you may not always want to do the same thing. In some
                            cases, you want to give an error message, in others you want to clip or substitute for the errant value or take some completely different
                            action. The programmer should have full control.

Elizabeth Rather quote #10:  Virtually every Forth application needs some kind of array structures. The reason that some general-purpose one might be "little used"
                             is because it's so easy to make a version that does *exactly* what the application needs rather than some generic definition. ...
                             The objective is to master the toolset and be able to think clearly about exactly what kind of arrays will be useful in your application
                             and then build exactly that kind.

The truth is the exact opposite of what is stated in these quotes. Verily, when programs are manually written (especially under deadline) they tend to be less than optimal --- the programmer uses only simple data-structures because they are easy to implement --- this is done instead of using more appropriate and more efficient data-structures such as what would typically be provided in a code library (for example, if you need a binary tree you aren't going to implement a self-balancing tree when you are under deadline, but you are just going to use a non-balanced tree and hope that the worst-case scenario of sorted data doesn't happen). It is quite rare to see any Forth program that uses any algorithm more complicated than what a programmer can implement in 10 minutes without any research (because the boss doesn't pay programmers to spend hours reading books on algorithms, or to spend hours writing complicated algorithms; he only pays them to crank out application code). Also, the algorithm doesn't really have to be "exactly right for the particular application;" only the superficial aspects of the program, such as what data is in the struct and which field is the key, will be application-specific. Programming is not nearly as complicated as non-programmers seem to think that it is --- it is not necessary to re-invent the wheel in every program --- a person's mental effort is better spent on solving the problem at hand using common data-structures rather than customizing data-structure algorithms for the application.

Before a person says, "it's so easy to build data structures that are exactly right," it would be a good idea to learn basic programming concepts such as what a struct is. None of the books from Forth Inc. describe what a struct is however! "Starting Forth" did describe CREATE DOES> words, and the data comma'd after the CREATE is effectively a struct, but the fields didn't have names and the code accessing the fields stepped through the fields using CELL+ (all the fields were comma'd in, so they were all cell-size). There is no evidence to indicate that Elizabeth Rather knows that the fields in a struct can have names rather than just numeric offsets. Also, CREATE builds only a single named struct, so a person who learns about CREATE DOES> from "Starting Forth" will not necessarily make the jump to building data-structures containing structs (nodes) connected with link pointers. The only data-structure discussed in "Starting Forth" was the array, and it wasn't general-purpose because it had to be rewritten using cut-and-paste for every primitive data type (char and word versions were provided in the book).

Quote #10 above comes from this thread, https://groups.google.com/forum/#!topic/comp.lang.forth/yTvD4nqPGA4%5B101-125%5D
Later on in the thread we see an attempt at a general-purpose array definer however:

On Sunday, August 9, 2015 at 7:30:10 PM UTC-7, Elizabeth D. Rather wrote:
> Here's [an array definer] presented in my Forth Application Techniques that I think is
> far more useful than the FSL version:
>
> : ARRAY ( n -- )   CREATE DUP , CELLS ALLOT
>     DOES> ( n -- a)   SWAP OVER @ OVER < OVER
>        1 < OR ABORT" Out of Range" CELLS + ;

Normally, when Elizabeth Rather posts a code snippet on comp.lang.forth, it is copied directly out of the "Starting Forth" book. This is the only example I know of in which she has posted code that she wrote herself (she is the author of "Forth Application Techniques," so I assume she wrote the code herself). Because this is the only known example of Forth code written by the self-proclaimed "leading expert" in Forth, it is worth examining. One problem is that the index starts at 1 rather than 0 (Elizabeth Rather's COBOL background is showing through). I will leave it to the reader to figure out what other problems there are, or just read the thread and get my comments there. This is very bad Forth code! If a first-week Forth student showed up on comp.lang.forth with this code and wanted to learn, I would be willing to help. Elizabeth Rather doesn't want to learn though --- she wants to teach!

Forth currently has the reputation of being a language for perpetual novices who don't really know anything about computer-science, because the Forth community has standardized on ANS-Forth. Of course, everybody is ignorant on a variety of subjects --- but an *ignoramus* is a person who is proud of his or her ignorance, who denounces people who do know about technology for being "egg-heads" and "geeks" etc., who has no intention of ever learning anything, and who sees the world as a trichotomy of bullies and brown-nosers and forest-dwellers --- the Stundurd is intended to rescue Forth from this rut, so we can move forward into the real-world of professional programming, and leave the corrupt world of COBOL far behind.


section 17.5) the name change

Originally, (June 10, 2015) the processor was called the FMITE and the language was called LOTD (Language Of The Damned). The name LOTD was introduced to dodge the disrepute of ANS-Forth. The name FMITE just means that the processor is small like a mite, but is mighty. The names actually contradict each other somewhat, as the 'F' in FMITE indicates Forth, but I had abandoned "Forth" as the name of the language LOTD.

The name LOTD didn't go over well with David Jaffe, the web-master of www.forth.org where my file FMITE.TXT was posted. He says:

------------------------------------------------------------------------------
If you are sincere in your beliefs, I suggest you send me an updated copy of
your last contribution with LOTD abbreviated to mean "Language of the
Developer" or something else that doesn't produce such a negative response. I
challenge you to do this.

Just one word can change the entire tenor of an article.
------------------------------------------------------------------------------

This is actually very disingenious --- he gives his blessing to Elizabeth Rather to post her ANS-Forth document on his website describing it as "standard" --- but he objects to the word "damned." Well, blessing one person is the same as damning everybody else --- playing god is a zero-sum game --- blessedness and damnation are opposite sides of the same coin, and you can't have one without the other. "Standard" is a damned vulgar name --- just this one word can change the entire tenor of an industry! Because of this vulgarity, ANS-Forth got quite a negative response when it came out in 1994 --- there was a mass exodus from Forth, and all but a handful of diehards switched over to C --- the name Standard Forth has hurt the Forth community far more than the name Language of the Damned ever could.

ANS-Forth was a marketing gimmick intended to convince the world that Forth Inc. sets the standard for the industry and that everybody else is dependent upon their leadership. The ANS-Forth document was rushed through and submitted to ANSI without ever being tested. There was no reference compiler written for ANS-Forth, so it couldn't be tested. The first ANS-Forth compiler written was SwiftForth($$$) and this was three years after ANS-Forth had been approved by ANSI. SwiftForth was a bug-ridden mess and was completely unusable. Even by version-2 SwiftForth still had major bugs --- for example, (LOCAL) would crash the system when used --- this was not a subtle bug that slipped through testing (the testers could hardly fail to notice a system crash), but this was indicative of there being no testing done at all prior to shipping the product to the customers (Elizabeth Rather routinely states that she hates locals, so the Forth Inc. programmers knew that she would never test the locals implementation in SwiftForth, so they didn't bother to test it either).

The ANS-Forth document is full of ambiguity, about how a feature may be one thing or may be another. For example, we have section 3.2.3.2:

"The control-flow stack may, but need not, physically exist in an implementation. If it does exist, it may be, but need not be, implemented using the data stack. The format of the control-flow stack is implementation defined. Since the control-flow stack may be implemented using the data stack, items placed on the data stack are unavailable to a program after items are placed on the control-flow stack and remain unavailable until the control-flow stack items are removed."

ANS-Forth was all about political concessions. Some compiler writers knew that it was a good idea to have the control-flow stack separate from the data-stack so that the meta-compiling word has access to its own data on the data-stack rather than have the control-flow data getting in the way. This fact was unknown at Forth Inc., most likely because there was nobody there who knew how to write a meta-compiling word. So the result was that a political concession was made to allow the compilers with a separate data-stack and control-stack be ANS-Forth compliant, although they are totally incompatible with SwiftForth that has the control-flow data on the data-stack. If somebody writes a program assuming that the control-flow stack is separate from the data-stack, it will fail on SwiftForth, and the programmer will be blamed for writing a non-standard program. It is totally meaningless for the ANS-Forth document to allow a feature that, when used, will result in a failure of portability and will be denounced as non-standard vendor-specific code. Elizabeth Rather was very focused on getting as many compiler writers as possible to sign on to Standard Forth because ANSI requires a list of contributors in order to approve a submission (popularity seems to be their only criteria). She made concessions allowing a wide variety of existing compilers to be ANS-Forth compliant, and never mind that none of them are compatible with each other. This is why the ANS-Forth document is full of ambiguity --- it is all about claiming to be standard --- but portability of programs was never a concern.

I'm not really against there being a standard --- if it is written by programmers --- but a standard written by a corporate salesperson is just vulgar.

I would challenge David Jaffe to raise the standards on his website (pun intended) --- if a document is submitted that is of abysmal technical quality and appears to have been written by a non-programming self-promoting salesperson, then it should not be allowed on the www.forth.org website as it tends to make all Forthers look bad --- he can start by removing the ANS-Forth document from his website --- www.forth.com would be more appropriate than www.forth.org for a document written by Elizabeth Rather that is really nothing more than self-promotion (the ANS-Forth document is just hot-air and puffery typical of any corporate marketing department, with no technical merit whatsoever).

In the meantime, I have changed the name from "Language of the Damned" to "Stundurd Forth" to appease David Jaffe, although most readers will consider the new name to be a step down (assuming that there is a level below damned). Stundurd Forth is a tacky and tasteless name, but in my favor it can be pointed out that I'm not demanding that every Forther accept my language as the standard, and that this humility is a step up from Elizabeth Rather who requires total allegiance. She says that I'm not an ANS-Forth programmer despite the fact that my novice-package works on SwiftForth, gForth, Win32Forth and VFX, and she says that John Passaniti is an ANS-Forth programmer despite the fact that all the code he posted on comp.lang.forth was written in Perl (but he praises ANS-Forth to the sky and attacks anybody who lacks his level of loyalty) --- so being an ANS-Forth programmer is all about brown-nosing and has nothing to do with actually writing ANS-Forth code --- ANS-Forth is a cult, not a language.

The Stundurd processor isn't the best design (it doesn't compare very well with the RACE processor from Testra), but it is a reasonable design. The Stundurd was designed to have very few registers, and to not require any primitive to do any branching, as these were the limitations the MiniForth was designed around. These limitations may not be valid anymore (Mark Wills says they aren't, and encourages me to "assume nirvana and go wild," but I constrained myself to what I was familiar with from the MiniForth of 20 years ago). The Stundurd processor could be a lot more powerful, but the design reflects the original name "mite" in being very small. Given a gigantic FPGA, it would make more sense to have multiple small cores rather than a single big processor, as this allows the code to be compatible between the big and small systems --- the design is intended to make general-purpose reusable code possible, so compatibility is important so code libraries can be used by any system. The processor is okay in so much as it competes against the AVR and MSP-430. Nowadays everybody uses the ARM Cortex though, and processor innovation is a moot point, so I doubt that anybody will ever actually implement the Stundurd in an FPGA. If there is a "standard," it is C on the ARM Cortex, but the concept of a "Standard Forth" is meaningless because there are so few Forth programmers remaining. I don't think that the situation would be improved by giving my language a name like "Language of the Developer" --- this isn't going to fool anybody into believing that it is being used for developing commercial applications --- I consider it to be tacky self-promotion for a person to pretend to be the establishment when that person is not the establishment, and I'm not going to do it.

The Forth-200x committee doesn't care what name this design has --- so long as they are Standard (with a capital 'S') then they can denounce everything else as a cheap imitation of themselves --- the following is the only comment that the FMITE received on comp.lang.forth:

On Sunday, July 5, 2015 at 2:36:05 AM UTC-7, Alex McDonald wrote:
> Then, as Hugh complains about Bernd's "faked quotations", his FMITE is no
> more than :NONAME syntactic sugar. Perhaps worse, as from what I read
> there the language does not permit use of the quotation outside of its
> enclosing word.

Forth-200x is a Procrustean Bed --- the Forth-200x committee expects every Forth programmer to fit in Forth-200x, and if you don't fit then they will cut off your feet to make you fit --- Forth-200x provides no positive benefit at all; it is entirely focused on giving people the psychological thrill of claiming that they set the standard for the industry and everybody has to follow them or be non-standard ("non-standard" is another word for "damned").

With Stundurd Forth I'm not demanding that everybody follow me, and damning them if they don't. Stundurd Forth is a "meme" (Richard Dawkins' term) that will hopefully become a juggernaut (although without the people getting crushed under its wheels). Franck Bensusan's Oforth looks interesting. Franck mentions his Oforth in this thread:
https://groups.google.com/forum/#!topic/comp.lang.forth/aN0nFHqJ14Q  This is his website: http://www.oforth.com/
Oforth is for multi-core desktop-computers (in 1985 I would have predicted a lunar colony as being more likely in the year 2015 than inexpensive laptop computers with dual-core 64-bit processors and over 4GB of RAM). Whether Oforth is the best solution to concurrency of lightweight tasks is debatable, but it is a step in the right direction. There is a huge difference between a desktop-computer and a micro-controller, so it is somewhat ridiculous to imagine that the same Forth system is going to be appropriate to both (Standard Forth is a jack of all trades and a master of none). There is plenty of room for innovation in the Forth world, but Standard Forth squelches all of it, so it is only Standard Forth that I'm opposed to --- if any fool ever declares that Stundurd Forth is the new standard in Forth and that every other Forth is damned, then I'll be opposed to that too.

Here is a cool meme that will go on the home page of my website when I eventually get organized enough to have a website:
http://memegenerator.net/instance/53401411
If this idea became widely accepted, society would improve considerably (you need to have seen the Matrix movie to grok this meme):


section 18.) comparison to Factor (like apples and oranges, but still some good ideas in Factor that can be borrowed)

The Factor language has quotations. I programmed in Factor a little, but got out of it because I didn't understand a lot of the concepts, and the documentation assumed that the novice already knew the concepts --- I thought it would be better to learn Scheme/Lisp first, where there is more documentation oriented toward novices. Also, although Factor is derived from Forth, but it is actually quite different from Forth and I didn't have any more common ground with Factor than I would with Scheme/Lisp. My foray into Factor was about five years ago --- I know more about the concepts now then I did then, although I'm still unfamiliar with a lot of computer-science that is fundamental to Scheme/Lisp and Factor. As a rule, people who have programmed only in C or Forth tend to be abysmally ignorant of computer-science --- I'm not an exception to this rule --- although I am a big step above the Forth-200x committee (informed by ignorance, driven by arrogance, and fascinated by complication).

One thing that is different about Factor, is that it uses quotations to replace both stack-juggling and control-structures.

As an example of using quotations to replace stack-juggling, the |DIP ( n xt -- n ) function would be implemented like this:
s" |dip" header
    HUFF12
s" |dip" header21
    >GP21
    TOR
    EXECUTE-GP
    RFROM
    RETURN

As another example of using quotations to replace stack-juggling, the |KEEP ( n xt -- n ) function (the quotation is expected to consume N) would be implemented like this:
s" |keep" header
    HUFF12
s" |keep" header21
    >GP21
    DUP                             \ N is duplicated before being stashed on the return-stack because the quotation will consume N
    TOR
    EXECUTE-GP
    RFROM
    RETURN

These could be used like this:

: -!  \ n adr --                    \ like +! but for subtraction
    { negate } |dip  +! ;

: and!  \ n adr --                  \ like +! but for logical-and
    { @ and } |keep  ! ;

Using traditional Forth this would be:

: -!  \ n adr --
    >r negate r>  +! ;

: and!  \ n adr --
    dup >r  @ and  r> ! ;

The use of >R and R> as shown above is widely considered to be the ugliest aspect of Forth, and mixing them up is a dyslexic accident waiting to happen.

Another possibility for -! and AND! would be:

: -!  \ n adr --
    swap negate  swap +! ;

: and!  \ n adr --
    dup @  rot and  swap ! ;

The use of SWAP and ROT as shown above is also ugly, although not quite as ugly as the >R R> versions. Stack juggling is confusing and the reader of the code often loses track of what data is being operated on. Words like DUP OVER and ROVER aren't too bad, but SWAP and ROT rearrange the stack order, which most Forth novices find disconcerting (experts get tangled up too, disturbingly often).

I didn't like |DIP and |KEEP (called DIP and KEEP in Factor) originally, but I've warmed up to the idea now --- the -! and AND! versions that use |DIP and |KEEP are actually much more readable than the traditional Forth versions. A simplistic compilation of |DIP and |KEEP is inefficient, but a smart optimizer should be able to convert the Factor-style code into the more efficient Forth-style code --- this is worthwhile, because the Factor-style code is more readable.

We can also have |2DIP |3DIP |2KEEP and |3KEEP that hold 2 or 3 cells on the return-stack, in addition to |DIP and |KEEP that hold 1 cell.

Factor also used quotations to replace control-structures. For example, the |IF ( flag true-xt false-xt ) function could be implemented like this:
s" |if" header
    HUFF12
s" |if" header21
    LINK
    >GP21
    TOR
    TOR
    ZERO?  EXECUTE-GP  UNLINK  ??
    RFROM
    RFROM12
    >GP21
    EXECUTE-GP
    UNLINK

On the FMITE, we had a DRFETCH>GP primitive that could be used instead of the RFROM RFROM12 >GP21 sequence. This makes |IF somewhat more efficient:

s" |if" header
    HUFF12
s" |if" header21
    LINK
    >GP21
    TOR
    TOR
    ZERO?  EXECUTE-GP  UNLINK  ??
    DRFETCH>GP
    EXECUTE-GP
    UNLINK

If |IF becomes popular, then the DRFETCH>GP primitive could be brought back, but this seems unlikely.

|IF could be used like this:

: test  \ a b flag -- a+b|a-b       \ FLAG is true for non-negative and false for negative
    { + } { - } |if ;

Using traditional Forth this would be:

: test  \ a b flag -- a+b|a-b
    if  +  else  -  then ;

I didn't like using quotations to replace control-structures originally, and I still haven't warmed up to the idea. I don't think that the |IF version is any more readable than the traditional Forth version. It would seem to be less readable when the quotations are multi-line, because the |IF is after the action-code rather than in front like in Forth and so the person reading the source-code doesn't know what the quotation is for until after he has read the quotation and come to the |IF at the end. Of course, the Factor crowd thinks that their way is more readable (few if any of them know Forth). A smart optimizer should be able to convert the Factor-style code into the more efficient Forth-style code --- this is not worthwhile though, because the Factor-style code is a dubious improvement in readability and may actually be worse.

Another issue here is that in Forth it is common to EXIT out of the middle of control structures. For example:

: test  \ a b sign -- a+b|a-b|a         \ SIGN is positive, negative or zero
    >r
    r@ 0> if  +  exit then
    r@ 0< if  -  exit then
    drop ;                              \ in Stundurd colon-words, any >R data left on the return-stack are automatically cleaned up

This can't be done using |IF or |WHILE because in Stundurd quotations can't exit out of the parent function.

Yet another issue here is that writing meta-compiling words would be quite complicated (maybe impossible). By comparison, in traditional Forth meta-compiling is easy as words like IF and WHILE are immediate and can be given to POSTPONE. Metacompiling is even easier than usual in Stundurd Forth because the control-stack is not the same as the data-stack but is distinct, so parameters can be passed into the meta-compiling word on the data-stack.

I can make |IF and |WHILE available, as they are mildly useful when the quotation xt is passed in as a parameter rather than written right there, but this won't be the idiomatic way to do control-structures because of all the limitations that this method imposes compared to traditional Forth. We do have |ITERATE and |UNTIL though, that are intended to replace ANS-Forth's DO loops.

Factor is a lot different than Forth, and I have only touched on a few minor points of comparison here (I expect the Factor enthusiasts to bring up myriad more points of comparison, claiming that Factor is ever so much better than Stundurd Forth). One thing that I liked about Factor was how it had a common data-structure (the "sequence" which is an array) that was used throughout all application programs. I did the same thing in my novice-package for ANS-Forth making singly-linked-lists my common data-structure, and this will also be done in Stundurd Forth.

Factor uses the curly brackets { } to surround sequences, and the square brackets [ ] to surround quotations. By comparison, Stundurd uses round brackets ( ) to surround linked-lists (similar to sequences), curly brackets { } to surround quotations, and square brackets [ ] to surround interpretation-mode code inside of colon words (not allowed in Factor). Programmers who use both languages will just have to get used to the fact that they aren't compatible in their bracket usage --- Stundurd is more similar to Scheme/Lisp than it is to Factor in its use of round-brackets for data. There was a language called Joy that preceded Factor and it used curly brackets for both quotations and data (Joy was similar to Scheme/Lisp in that code and data were the same thing) --- the compiler is actually simplified considerably however, to have a clear distinction between quotations and linked-lists of data (as done in both Factor and Stundurd), because code and data aren't the same thing in a compiled language.

What I primarily didn't like about Factor is that it is dynamic-OOP. Every datum has a tag field that indicates its type. The tag field in Factor is 3 bits, so there are 8 data types (Racket has a 2-bit tag and 4 data types). Dynamic-OOP languages generally always have garbage-collection. By comparison, Forth can't really have garbage-collection because there is no intrinsic way to tell the difference between a pointer and an integer, so there is no good way to keep track of where all the pointers to a particular datum are. Dynamic-OOP is always going to be inefficient --- this is okay for a desktop-computer programming languages that is used for scripting and web-server programs --- this is not okay for micro-controllers though. Slava Pestov told me that the ColdFire was the smallest processor he could conceive of Factor running on. The ColdFire is a gigantic 32-bit processor though! The majority of processors used in the real world are 8-bit or 16-bit. The Stundurd has a lot wider application than the ColdFire or the ARM or any other 32-bit processor. Slava chose the velociraptor as Factor's totem animal; apparently the analogy here is that Scheme/Lisp is like an allosaurus, and that Factor is smaller and quicker like a velociraptor (Common Lisp is so big that its totem animal should be the tyrannosaurus). In keeping with the theropod theme, I choose the camposaurus as Stundurd's totem animal, which was quite tiny and presumably wicked quick (also: it lived in Arizona which is where I live, so it is my "homie"). As a rough estimate, the camposaurus was ~50 pounds and maybe 3 meters long, the velocirapter was ~500 pounds, the allosaurus was ~1000 pounds, and the tyrannosaurus was ~2000 pounds (the camposaurus was a forerunner of all the bigger theropods, with the T-Rex being at the end of a lengthy and quite scary evolutionary path). Only an incomplete skeleton of the camposaurus has been found, so we don't know whether it had a snout full of teeth or a beak like a bird (both representations have been done in different museums) --- this is also a good analogy for the Stundurd, as I predict that people who don't know anything about the Stundurd will make up their own "facts" (sadly typical behavior on comp.lang.forth). Earlier, we had an Elizabeth Rather quote: "I think [the paranoia about reentrancy] is all about mythical dragons." Well, the camposaurus is that dragon!

Although Factor is not practical in the real-world (the micro-controller world), Factor does have a lot of good ideas that can be borrowed for Stundurd Forth.


section 19.) implementation strategies (for HDL programmers)

The author (Hugh Aguilar) is just a programmer, but doesn't do hardware-design (Verilog, VHDL, etc.). The author's experience was to write the MFX (MiniForth Cross-compiler) for the MiniForth processor (now called the RACE processor) when employed at Testra. This processor is described here:
http://www.testra.com/Forth/RACE.htm
The webpage says this: "Getting the miniForth up and running was one of the easiest parts of the job, The simulation code for the 27 primitives needed to build the Forth kernel took only a few days to write and debug." I was the one who did that, and I don't remember it being trivial. The whole project took most of one year (spanning 1994 and 1995). The goal of the project was to build a processor that could run the motion-control program faster than it currently was running on the Dallas 80c320 (this was necessary to support a laser-etcher that required quick changes of direction so the laser would go as fast for curved lines as straight lines, because the laser burns splotches in the material if it goes slow or stutters). I wrote MFX in UR/Forth (from Laboratory Microsystems). This included an assembler, simulator and Forth cross-compiler. The motion-control program was the only program compiled under MFX when I was there (and, as far as I know, after I left).

The MiniForth was built on a Lattice isp1048 PLD. The hardware design was written in an HDL (hardware-design-language) that was proprietary to Testra (it was written in UR/Forth). The RACE is the MiniForth upgraded to an FPGA; the hardware design is now in VHDL, although it has a Forth front-end to ease the transition from the old Forth HDL written in UR/Forth --- the RACE was introduced after I left Testra; they continued to use MFX for the RACE as the RACE is pretty much the same as the MiniForth from a software standpoint.

The MiniForth was Harvard Architecture. The Forth threaded-code was in data-memory along with the data. An xt was 16-bit (we didn't have the term xt in Forth-83; we called it an "instruction word"). See Appendix-A in Testra's webpage for the format of the xt. The low bit of the xt indicated whether it was a primitive (written in machine-code) or a colon word (written in Forth). If the low-bit was 1, it was a primitive and the upper 15 bits was the cell-aligned address in program-memory. If the low-bit was 0, it was a colon word and the upper 15 bits was the cell-aligned address in data-memory. The machine-code consisted of 16-bit opcodes. See Appendix-B in Testra's webpage for the format of the opcodes. Each opcode could have up to five instructions packed into it; each opcode executed in one clock cycle, and all five instructions executed simultaneously. My assembler would rearrange the instructions from their order in the source-code and pack them together into the opcodes. If it couldn't pack all five slots with instructions from the source-code, then it would insert NOP instructions in the slots those empty slots. The goal of the assembler was to rearrange the instructions in such a way as to minimize the number of NOP instructions inserted, while yet guaranteeing that the program did the same thing as if the instructions were assembled one per opcode in the same order as they had been found in the source-code. The code for NEXT almost always parallelized with the surrounding code, so it took zero clock cycles. The assembler also generated a program that ran on the host computer and simulated the execution of the MiniForth at the register level. The assembler/simulator was the most difficult part of MFX to write --- the Forth cross-compiler was pretty straight-forward.

The Stundurd processor would presumably be implement similarly to the MiniForth. It would be Harvard Architecture, with the 32KB of non-volatile memory (program-memory and constant-memory) and the 32KB of RAM (data-memory) having one set of address and data buses. In this case, all primitives would be written in a machine-code that executes in a small non-volatile memory having its own address and data buses --- the machine-code would be implemented in the HDL and executed in hardware --- this would be a very low-level machine-language that doesn't support branching. It might also be possible to implement the Stundurd primitives directly in HDL rather than in a low-level assembly-language --- I've never seen anything like this done, but have heard that it is possible on the big FPGA chips available nowadays.

It is assumed that interrupts only occur between primitives. The UDIV21 primitive is pretty time consuming though, and may take so long that an interrupt could be lost during its execution. If this is the case, then UDIV21 will have to be modified to do a single step of the division (there are 16 steps), so this step can be put in an assembly-language loop (similar to how division is done on the PIC24). This will allow an interrupt to occur in the middle of the division. The downside is that the division would be slower than if it were a single instruction as the design currently provides. Losing interrupts was an issue on the MiniForth --- that was 20 years ago though --- it is possible that with modern high-speed FPGAs an entire division can be done so quickly that no interrupts get lost. Also, in a multi-core Stundurd system, there would be no interrupts (the RETURN-ISR would be replaced by a SLEEP primitive) --- so the issue of losing interrupts would be solved.

The data-bus for data-memory is 8-bit in the plain-vanilla version of the Stundurd. A good first-step toward boosting the speed would be a 16-bit data-bus. The data-stack and return-stack contain only cells that are cell-aligned, so these should be an easy win. If global data is cell-aligned, then that should also be an easy win. Some micro-controllers work with a lot of 8-bit data --- C@ and C! seem to get used more than @ and ! --- still though, a 16-bit data-bus for data-memory should be the best first-step toward boosting the speed of the Stundurd. Also, 12-bit ADC and DAC ports are common, and we want to be able to read and write these without any stuttering so the datum doesn't get corrupted.

The Stundurd has been designed to have as few registers as possible, on the assumption that registers are expensive to implement (they were expensive on the Lattice PLD, which is why the MiniForth had so few registers, and presumably they are expensive on an FPGA too). An early design for the Stundurd had a ROS register (for the third item on the stack ) in addition to SOS and TOS (for the second and first items), and it had primitives that huffed data into all three registers. ROS got discarded to reduce the register count though. If a chip can support more registers than the plain-vanilla Stundurd has, ROS is a bad idea because this breaks compatibility with the plain-vanilla ROS-less version. Instead, the high-performance version should get an RTOS register to hold the top value of the return-stack. If this is done, all of the primitives that access the return-stack will need their implementation modified to use RTOS. Their behavior will stay the same however, so the programmer will not know the difference; all Stundurd programs will run on versions of the Stundurd with or without the RTOS register, and they won't need to be recompiled. Adding the RTOS register should significantly boost the speed of the RFETCH12 primitive.

It is also possible for the Stundurd to have a small (4 byte) prefetch-queue for the instructions (similar to what we had on the Intel 8088 or the MC6812). The data-bus for program memory is 8-bit. Many of the Stundurd instructions are "prefetch-positive" (this is Michael Abrash's term from his Zen book). This means that they take so long to execute, that they provide enough time for the prefetch-queue to be loaded in the background so the next instruction is ready to be used without any delay between instructions executing. The prefetch-queue helped the 8088 a lot because the 8088 had many multi-byte instructions that took a long time to trundle in from memory (we have already seen examples in this article of how bloated x86 code is), and so quite a lot of instructions were prefetch-positive. By comparison, most of the Stundurd instructions are one-byte and the rest are two-byte, so there isn't much of a delay in loading them anyway. Still though, a prefetch-queue (program-memory cache) should boost the speed somewhat. A data-memory cache would not be worthwhile (this only works on Pentium-class processors because they have multiple cache lines, but such complexity is way beyond anything that could realistically be implemented in an FPGA).

The Stundurd is intended to be small size, low cost and low power-consumption, so the plain-vanilla version should be popular on this basis. It is important that more high-performance versions should be compatible with the basic version so as not to obsolete any code. Both techniques described above for boosting the speed (a 16-bit data-bus and a prefetch-queue) have this advantage of not changing the instruction set at all.

If I knew any HDL I would do all of this myself --- I don't though, so I am making the design public in the hopes that somebody who does know an HDL can implement the processor --- my contribution would just be the cross-compiler for Stundurd.


section 19.5) an interesting suggestion

Michael Barry says this:

----------------------------------------------------------------------------------------------------------------------------------------------------------------------
In the simplest FMITE, I believe there are two internal states for the parameter stack: huffed and puffed.  If the FMITE keeps an internal flag that keeps track of this, it can insert a huff or puff automatically BEFORE the currently decoded instruction, but only if the current state is wrong for that particular instruction.  Latency would be a maximum of a single huff or puff, and would usually be zero.  By putting this atomic latency in its own clock slot (BEFORE the current instruction, not AFTER), the maximum clock speed wouldn't hardly suffer at all.  All of your mnemonics that have a suffix like 01, 12, 21, could be consolidated into a single op-code and mnemonic with no suffix, because the cpu would know by the current state and the op-code it has just decoded whether or not it will have to insert a one cycle delay to huff or puff.  HUFF01, HUFF12, and PUFF21 could be completely eliminated from the op-code matrix, because they would be internalized, and only used as dictated by the current instruction stream.

There would be no need to worry about leaving the processor in any given huff/puff state after any instruction or exit (or interrupt, for that matter), because any necessary state changes would be handled by the cpu when the following instruction is fetched and decoded.  I believe that some of the Burroughs mainframes were doing this 50 years ago, so it's a proven strategy.  The best analogy that comes to mind is a manual transmission vs. an automatic:  your assembly code examples expend a lot of effort to keep all the huffers and puffers in harmony by manually clutching and shifting gears (states) as needed.  You don't have to upshift or downshift an automatic, you just put it in "drive" and let it decide the best gear for the circumstances. In my experience, it usually makes the most efficient choice for the given road (instruction stream), unless it's broken.  And you don't have to worry about spilling your coffee or dropping your cigarette by having to reach for the gearshift in traffic.  It should also be possible to get the compiler to recognize and favor more efficient sequences (like NIP DROP instead of DROP DROP, so the cpu doesn't have to work so hard automatically huffing and puffing).

----------------------------------------------------------------------------------------------------------------------------------------------------------------------

Michael Barry is a professional auto-mechanic, which is presumably why his explanation concluded with an automobile analogy. As an historical note, Henry Ford originally wanted an automatic transmission because he didn't believe that the average American was capable of learning how to operate a clutch, and he expected that if only a manual transmission were offered then automobiles would only be purchased by "gear heads" (the term for technology enthusiasts in the early 20th century), whereas the common people would continue to use horses. Unfortunately, his engineers informed him that the automatic-transmission technology was not ready for prime-time yet, so he had to go with a manual transmission. The people managed, although 50 years later when automatic-transmissions were introduced everybody jumped on the technology as they apparently had had quite enough of spilling their coffee and dropping their cigarettes. Michael programs as a hobby, mostly in 6502 assembly language for retro computers from the 1980s.

His idea is pretty good. There would be a one-bit register flag (lets call it SV for "SOS valid") that would be set to TRUE if SOS has the second-on-stack value in it or set to FALSE if SOS is invalid. Each primitive would set SV appropriately when it concluded. Most of the primitives would also examine SV before beginning, and either huff a datum into SOS or puff a datum out of SOS depending upon which they need. Some primitives, such as LIT-PLUS don't care if SOS is valid or not because they only work with TOS and so they would ignore SV and leave it as-is for the next primitive to worry about.

The advantage of this scheme is that there would be fewer primitives needed to do the same thing as currently being done. Right now, there is a lot of redundancy such as SWAP12 and SWAP22 that essentially do the same thing, but are only different in regard to whether they expect SOS to be valid or not. All of these redundant primitives could be replaced with a single primitive, such as SWAP for SWAP12 and SWAP22. We still have 64 primitives total available though, so a lot of what currently are macros could become primitives --- for example, we could have a TUCK primitive (currently we have TUCK12 and TUCK22 macros, each expanding to two primitives). Also, a single primitive only takes up one byte, so it could fit in the skip-area of a skippy primitive along with another primitive, reducing the need to put a BRANCH in the skip-area and the code elsewhere. The overall program would be smaller --- reducing bloat could be an issue for big programs (we only have 32KB of non-volatile memory, and only 16KB of that is accessible by CALL) --- also, reducing bloat increases speed because less time is spent fetching and decoding opcodes.

The disadvantage is that most of the primitives would be slower because they have to test SV before beginning and also set SV at the end. This likely won't make much of a difference in an FPGA. In an emulation however, it could make a big difference. The AVR is not too bad, because the T flag could be used as SV, but most processors (such as the MSP-430 or PIC24) would require a 16-bit register to be used for SV which is wasteful of resources (it might be possible to use the Carry flag, although you would have to be careful not to accidently clobber it in your NEXT code). Another disadvantage is that this scheme requires primitives to be able to branch internally (depending upon the state of SV at the beginning). My experience with the MiniForth, is that primitives can't branch internally --- I assume that this is very expensive to implement in an FPGA --- Mark Wills says that I'm thinking in terms of 20-year-old technology and that modern FPGAs are much more powerful and don't have this limitation. I'm not familiar enough with FPGAs to know if this is true or not (maybe it is only true for big expensive FPGAs but not for small inexpensive FPGAs).

Right now, I'm sticking with the simple plan of having the huffing and puffing figured out at compile-time (the cross-compiler generates either SWAP12 or SWAP22 as appropriate). Michael's idea with this being done at run-time is something to consider though --- maybe a second version of the processor can do this.


section 20.) conclusion

I've never met any Forth or C programmer who knew what lambda functions are --- with Stundurd Forth, I hope to attract educated programmers (the Lisp and Factor crowd) to the micro-controller world, and displace the bit-twiddlers who don't really know anything about computer science --- Stundurd can provide an opportunity for educated programmers to make money. There is money in writing programs for micro-controller circuit-boards, but there is no money in writing programs in Lisp or Factor (or any other language) for desktop computers. Lisp has lambda functions that make it an elegant language, but it also has tagged-data and garbage-collection that kill the performance (abysmal performance is why Lisp can't be used on micro-controllers, which are usually 16-bit). Writing desktop-software in horizontal markets is pointless, as it is almost always GPL and given away for free --- writing desktop-software in vertical markets is also largely pointless, as it gets pirated pretty soon. The good thing about micro-controllers however is that they secure the firmware so it can't be pirated by the user of the circuit-board. Unfortunately, micro-controllers are currently programmed primarily in C, which is an inelegant, artless and just plain ugly language (my description of any language that lacks intrinsic support for lambda functions). When C is your only hammer, every problem looks like your thumb! Hopefully with the advent of the Stundurd, the C language will become obsolete --- micro-controller code will become elegant (like Lisp but better) and efficient (like C but better).

Micro-controllers are where the money is, but ANS-Forth is primarily only for desktop-computers as it was designed to support C-language token-threaded interpreters such as gForth and hence is too big and cumbersome for micro-controllers (gForth runs on the Raspberry-Pi under Linux, which the ANS-Forth enthusiasts consider to be a micro-controller). ANS-Forth also mixes compile-time code and run-time code together indiscriminately which makes the language quite confusing (there is no way to examine an xt and determine if it is supposed to be executed at compile-time or run-time, whether it is immediate or non-immediate, or what word-list it was defined in). The famous Forther Jeff Fox (sadly passed away now) told me that Charles Moore had commented that ANS-Forth was 100 times more complicated than necessary. Shortly thereafter, the Forth-200x project began. Charles Moore and Jeff Fox both thought that the name Forth-200x was a snarky rejoinder to Charles' comment, implying that Forth-200x would be 200 times more complicated than necessary, which was the logical next step in the fools' parade that Forth had become. Only much later did they realize that the "200x" meant that it was supposed to be released sometime in the 2000-2009 decade (now, in the year 2015, Forth-200x still hasn't been released because the committee continually thinks up new layers of useless complication to pile on top of old layers of useless complication). Such a grossly over-complicated language is completely inappropriate for a micro-controllers! The Forth-200x committee has lost their way and gone astray, forgetting Forth's roots in micro-controller applications (Charles Moore's famous Kitt Peak telescope controller). If Factor is a velociraptor, then Forth-200x is Godzilla; 10 times the size and 100 times the ugly --- but Stundurd is the practical solution for real-world micro-controllers! --- the Stundurd has 1/100th the memory-usage, 1/100th the power consumption, and 100 times the speed (when implemented in an FPGA).